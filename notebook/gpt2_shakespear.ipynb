{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "project_root = os.path.dirname(os.getcwd())\n",
    "sys.path.append(f\"{project_root}/src\")\n",
    "sys.path.append(f\"{project_root}/third_party\")\n",
    "\n",
    "os.environ[\"RAY_DEDUP_LOGS\"] = \"0\"\n",
    "os.environ[\"RAY_COLOR_PREFIX\"] = \"0\"\n",
    "\n",
    "from config import gpt2_cfg as cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-17 10:20:31,307\tINFO worker.py:1772 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "2024-08-17 10:20:31,317\tINFO packaging.py:530 -- Creating a file package for local directory '/workspaces/CaiZi'.\n",
      "2024-08-17 10:20:31,330\tINFO packaging.py:358 -- Pushing file package 'gcs://_ray_pkg_1e2ac1752fe40a8c.zip' (4.66MiB) to Ray cluster...\n",
      "2024-08-17 10:20:31,355\tINFO packaging.py:371 -- Successfully pushed file package 'gcs://_ray_pkg_1e2ac1752fe40a8c.zip'.\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "if ray.is_initialized():\n",
    "    ray.shutdown()\n",
    "\n",
    "ray.init(\n",
    "        runtime_env={\n",
    "            \"env_vars\": {          \n",
    "                \"PYTHONPATH\": \"$PYTHONPATH:\" + cfg.project_root + \"/src\",\n",
    "                \"RAY_DATA_VERBOSE_PROGRESS\": \"1\",\n",
    "            },\n",
    "            \"working_dir\": cfg.project_root,\n",
    "            \"excludes\": [\n",
    "                \"/bazel-*\",\n",
    "                \".git\",\n",
    "                \"*.pyc\",\n",
    "                \"/__pycache__\",\n",
    "                \"/outputs\",\n",
    "                \"/model\",\n",
    "            ],\n",
    "        },\n",
    "        ignore_reinit_error=True,\n",
    "    )\n",
    "\n",
    "# convience for debugging\n",
    "ray.data.DataContext.get_current().execution_options.verbose_progress = True\n",
    "ray.data.DataContext.log_internal_stack_trace_to_stdout = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "data_sources = [ Path(item[\"path\"]) for item in cfg[\"dataset\"]]\n",
    "text_document_paths = ray.data.from_items(data_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from document_processor import TextDocumentProcessor\n",
    "train_text_document_processor = TextDocumentProcessor(section=\"train\")\n",
    "train_texts=text_document_paths.map(train_text_document_processor)\n",
    "\n",
    "validate_text_document_processor = TextDocumentProcessor(section=\"validate\")\n",
    "validate_texts=text_document_paths.map(validate_text_document_processor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from token_processor import CharTokenizer\n",
    "tokenizer = CharTokenizer()\n",
    "train_tokens = train_texts.map(tokenizer)\n",
    "validate_tokens = validate_texts.map(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chunk_processor import ChunkProcessor\n",
    "\n",
    "chunk_processor = ChunkProcessor(block_size=cfg[\"124M\"][\"block_size\"],stride=cfg[\"124M\"][\"stride\"])\n",
    "train_chunked_tokens = train_tokens.flat_map(chunk_processor)\n",
    "validate_chunked_tokens = validate_tokens.flat_map(chunk_processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-17 10:20:47,178\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-17_10-20-30_591698_103708/logs/ray-data\n",
      "2024-08-17 10:20:47,178\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(CharTokenizer)->FlatMap(ChunkProcessor)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3795b83be3ed434791fd8fa9476c1cf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Map(TextDocumentProcessor)->Map(CharTokenizer)->FlatMap(ChunkProcessor) 1: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46e2db0ce9be450eae974b29533f0510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3921\n"
     ]
    }
   ],
   "source": [
    "row = train_chunked_tokens.take_all()\n",
    "print(len(row)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import torch\n",
    "import torchmetrics\n",
    "\n",
    "from model.GPT import GPT\n",
    "from model.gpt_lr_scheduler import GPTLRScheduler\n",
    "from utility import resume_checkpoint, save_checkpoint\n",
    "\n",
    "def prepare_gradient_scaler(use_amp=True):\n",
    "    return torch.amp.GradScaler(enabled=use_amp)\n",
    "\n",
    "\n",
    "def resume_training(best_checkpoint_dir, model, optimizer,scaler, device):\n",
    "    if os.path.exists(best_checkpoint_dir):\n",
    "        checkpoint = ray.train.Checkpoint.from_directory(best_checkpoint_dir)\n",
    "    else:\n",
    "        checkpoint = None\n",
    "    if checkpoint:\n",
    "        best_epoch, best_perplexity = resume_checkpoint(\n",
    "            model, optimizer, scaler, checkpoint,str(device)\n",
    "        )\n",
    "        epoch_start = best_epoch\n",
    "        print(f\"Resumed training from best_epoch {best_epoch},best_perplexity {best_perplexity}\")\n",
    "    else:\n",
    "        print(f\"Checkpoint not found, starting from epoch 0\")\n",
    "    return epoch_start,best_epoch,best_perplexity\n",
    "\n",
    "\n",
    "def prepare_metric(device):\n",
    "    metric = torchmetrics.text.Perplexity().to(device)\n",
    "    return metric\n",
    "\n",
    "\n",
    "def prepare_loss_function():\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    return loss_function\n",
    "\n",
    "\n",
    "def prepare_lr_scheduler(warmup_steps, max_steps, max_lr, min_lr,decay_lr,optimizer):\n",
    "    scheduler = GPTLRScheduler(\n",
    "        optimizer,\n",
    "        warmup_steps=warmup_steps,\n",
    "        max_steps=max_steps,\n",
    "        max_lr=max_lr,\n",
    "        min_lr=min_lr,\n",
    "        decay_lr=decay_lr,        \n",
    "    )\n",
    "\n",
    "    return scheduler\n",
    "\n",
    "\n",
    "def prepare_optimizer(weight_decay, max_lr,beta1,beta2, model, device):\n",
    "\n",
    "    # start with all of the candidate parameters\n",
    "    param_dict = {pn: p for pn, p in model.named_parameters()}\n",
    "    # filter out those that do not require grad\n",
    "    param_dict = {pn: p for pn, p in param_dict.items() if p.requires_grad}\n",
    "    # create optim groups. Any parameters that is 2D will be weight decayed, otherwise no.\n",
    "    # i.e. all weight tensors in matmuls + embeddings decay, all biases and layernorms don't.\n",
    "    decay_params = [p for n, p in param_dict.items() if p.dim() >= 2]\n",
    "    nodecay_params = [p for n, p in param_dict.items() if p.dim() < 2]\n",
    "    optim_groups = [\n",
    "        {\"params\": decay_params, \"weight_decay\": weight_decay},\n",
    "        {\"params\": nodecay_params, \"weight_decay\": 0.0},\n",
    "    ]\n",
    "\n",
    "    num_decay_params = sum(p.numel() for p in decay_params)\n",
    "    num_nodecay_params = sum(p.numel() for p in nodecay_params)\n",
    "    print(\n",
    "        f\"num decayed parameter tensors: {len(decay_params)}, with {num_decay_params:,} parameters\"\n",
    "    )\n",
    "    print(\n",
    "        f\"num non-decayed parameter tensors: {len(nodecay_params)}, with {num_nodecay_params:,} parameters\"\n",
    "    )\n",
    "\n",
    "    # Create AdamW optimizer and use the fused version if it is available\n",
    "    fused_available = \"fused\" in inspect.signature(torch.optim.AdamW).parameters\n",
    "    use_fused = fused_available and \"cuda\" in str(device)\n",
    "    extra_args = dict(fused=True) if use_fused else dict()\n",
    "\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        optim_groups,\n",
    "        lr=max_lr,\n",
    "        betas=(beta1, beta2),\n",
    "        eps=1e-8,\n",
    "        **extra_args,\n",
    "    )\n",
    "\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def prepare_data():\n",
    "    train_data_shard = ray.train.get_dataset_shard(\"train\")\n",
    "    validate_data_shard = ray.train.get_dataset_shard(\"validate\")\n",
    "    return train_data_shard, validate_data_shard\n",
    "\n",
    "\n",
    "def prepare_model(\n",
    "    vocab_size,\n",
    "    dimension_embedding,\n",
    "    block_size,\n",
    "    num_layers,\n",
    "    num_headers,\n",
    "    drop_rate,\n",
    "    bias,\n",
    "):\n",
    "    model = GPT(\n",
    "        vocab_size,\n",
    "        dimension_embedding,\n",
    "        block_size,\n",
    "        num_layers,\n",
    "        num_headers,\n",
    "        drop_rate,\n",
    "        bias,\n",
    "    )\n",
    "    model = torch.compile(model)\n",
    "    model = ray.train.torch.prepare_model(model)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import ray.train\n",
    "import ray.train.torch\n",
    "\n",
    "\n",
    "def train_workload_per_worker(cfg):\n",
    "    vocab_size = cfg[\"vocab_size\"]\n",
    "    dimension_embedding = cfg[\"dimension_embedding\"]\n",
    "    block_size = cfg[\"block_size\"]\n",
    "    num_layers = cfg[\"num_layers\"]\n",
    "    num_headers = cfg[\"num_headers\"]\n",
    "    drop_rate = cfg[\"drop_rate\"]\n",
    "    bias = cfg[\"bias\"]\n",
    "    check_frequency = cfg[\"check_frequency\"]\n",
    "    physical_training_batch_size_per_worker = cfg[\"physical_training_batch_size_per_worker\"]\n",
    "    physical_validate_batch_size_per_worker = cfg[\"physical_validate_batch_size_per_worker\"]\n",
    "    num_epoch_per_worker = cfg[\"num_epoch_per_worker\"]\n",
    "    resume_training = cfg[\"resume_training\"]\n",
    "    best_checkpoint_dir = cfg[\"best_checkpoint_dir\"]\n",
    "    warmup_steps = cfg[\"warmup_steps\"]\n",
    "    max_steps = cfg[\"max_steps\"]\n",
    "    max_lr = cfg[\"max_lr\"]\n",
    "    min_lr = cfg[\"min_lr\"]\n",
    "    beta1 = cfg[\"beta1\"]\n",
    "    beta2 = cfg[\"beta2\"]\n",
    "    decay_lr = cfg[\"decay_lr\"]\n",
    "    weight_decay = cfg[\"weight_decay\"]\n",
    "    total_tokens_per_logical_batch_per_worker = cfg[\"total_tokens_per_logical_batch_per_worker\"]\n",
    "    data_type = cfg[\"data_type\"]\n",
    "\n",
    "    floating_point_precision = {\n",
    "        \"float32\": torch.float32,\n",
    "        \"bfloat16\": torch.bfloat16,\n",
    "        \"float16\": torch.float16,\n",
    "    }[data_type]\n",
    "\n",
    "    rank = ray.train.get_context().get_world_rank()\n",
    "    device =ray.train.torch.get_device()\n",
    "    use_amp = (floating_point_precision==\"float16\")\n",
    "\n",
    "    torch.manual_seed(1337 + rank)\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "    # data\n",
    "    train_data_shard, validate_data_shard = (\n",
    "        prepare_data()\n",
    "    )\n",
    "\n",
    "    # GPT model\n",
    "    model = prepare_model(\n",
    "        vocab_size,\n",
    "        dimension_embedding,\n",
    "        block_size,\n",
    "        num_layers,\n",
    "        num_headers,\n",
    "        drop_rate,\n",
    "        bias,\n",
    "    )\n",
    "\n",
    "    # optimizer\n",
    "    optimizer = prepare_optimizer(\n",
    "        weight_decay, max_lr,beta1,beta2, model, device\n",
    "    )\n",
    "\n",
    "    # initialize a GradScaler. Enable AMP for float16.\n",
    "    # According to the pytorch documentation:\n",
    "    #     \"When entering an autocast-enabled region, Tensors may be any type. \n",
    "    #     You should not call half() or bfloat16() on your model(s) or inputs \n",
    "    #     when using autocasting\"\n",
    "    scaler = prepare_gradient_scaler(use_amp=use_amp)\n",
    "\n",
    "    # lr scheduler\n",
    "    scheduler = prepare_lr_scheduler(\n",
    "        warmup_steps, max_steps, max_lr, min_lr,decay_lr, optimizer\n",
    "    )\n",
    "\n",
    "    # loss function\n",
    "    loss_function =prepare_loss_function()\n",
    "\n",
    "    # metrics\n",
    "    metric = prepare_metric(device)\n",
    "\n",
    "    # ====== Resume training state from the checkpoint. ======\n",
    "    epoch_start = 0\n",
    "    best_perplexity = float(\"inf\")\n",
    "    best_epoch = 0\n",
    "\n",
    "    if resume_training:\n",
    "        epoch_start, best_epoch,best_perplexity  = (\n",
    "            resume_training(best_checkpoint_dir, \n",
    "                                                            model, \n",
    "                                                            optimizer,\n",
    "                                                            scaler,\n",
    "                                                            device)\n",
    "            )\n",
    "        \n",
    "\n",
    "    report_metrics = {\n",
    "        \"rank\": rank,\n",
    "        \"epoch\": epoch_start,\n",
    "        \"token_total_\": 0,  # total tokens processed\n",
    "        \"token_process_time_ms\": 0.0, # time in ms\n",
    "        \"token_per_second\": 0.0,    # speed \n",
    "    \n",
    "        \"logical_train_loss\": 0.0,\n",
    "        \"logical_batch_count\": 0,\n",
    "    \n",
    "        \"norm\": 0.0,\n",
    "        \"validate_loss\": 0.0,\n",
    "        \"perplexity\": 0.0,\n",
    "        \n",
    "        \"best_epoch\": best_epoch,\n",
    "        \"best_perplexity\": best_perplexity,\n",
    "    }\n",
    "\n",
    "    assert (\n",
    "        total_tokens_per_logical_batch_per_worker % (physical_training_batch_size_per_worker * block_size) == 0\n",
    "    ), \"total_batch_size must total_tokens_per_logical_batch_per_worker divisible by physical_training_batch_size_per_worker*block_size\"\n",
    "\n",
    "    logical_batch_size_per_worker = (\n",
    "        total_tokens_per_logical_batch_per_worker // block_size\n",
    "    )  # logical batch size\n",
    "\n",
    "    gradient_accumulation_steps = (\n",
    "        logical_batch_size_per_worker // physical_training_batch_size_per_worker\n",
    "    )\n",
    "\n",
    "    print(f\"total_tokens_per_logical_batch_per_worker: {total_tokens_per_logical_batch_per_worker}\")\n",
    "    print(f\"gradient_accumulation_steps: {gradient_accumulation_steps}\")\n",
    "\n",
    "    \n",
    "\n",
    "    for epoch in range(epoch_start + 1, num_epoch_per_worker + 1):\n",
    "        token_processed = 0\n",
    "        \n",
    "        model.train()\n",
    "\n",
    "        current_rank = ray.train.get_context().get_world_rank()\n",
    "        report_metrics[\"rank\"] = current_rank\n",
    "        report_metrics[\"epoch\"] = epoch\n",
    "\n",
    "        logical_train_loss = 0\n",
    "        logical_batch_count = 0\n",
    "        t0 = time.time()\n",
    "\n",
    "        for logical_batch in train_data_shard.iter_torch_batches(\n",
    "            batch_size=logical_batch_size_per_worker,\n",
    "            drop_last=False,\n",
    "            local_shuffle_buffer_size=1000,\n",
    "        ):\n",
    "            logical_batch_count += 1\n",
    "            logical_input_ids = logical_batch[\"input_ids\"]\n",
    "            logical_target_ids = logical_batch[\"target_ids\"]\n",
    "\n",
    "            \n",
    "            for step in range(gradient_accumulation_steps):\n",
    "                physical_input_ids_in_current_step = logical_input_ids[step : step + physical_training_batch_size_per_worker]\n",
    "                physical_target_ids_in_current_step = logical_target_ids[step : step + physical_training_batch_size_per_worker]\n",
    "                \n",
    "                # https://pytorch.org/tutorials/recipes/recipes/amp_recipe.html\n",
    "                with torch.autocast(device_type=device.type,dtype=floating_point_precision,enabled=use_amp,):\n",
    "                    logits = model(physical_input_ids_in_current_step)\n",
    "                    physical_loss = loss_function(logits.flatten(0, 1),physical_target_ids_in_current_step.flatten(),)\n",
    "                    physical_loss = (physical_loss / gradient_accumulation_steps)  # normalize the loss to account for the gradient accumulation\n",
    "\n",
    "                \n",
    "                # require_backward_grad_sync is set to True for the last step in the gradient accumulation  \n",
    "                # to speed up the training process by reducing the synchronization overhead across workers.\n",
    "                model.require_backward_grad_sync = (step == gradient_accumulation_steps - 1)\n",
    "                \n",
    "                # Scales loss.  Calls backward() on scaled loss to create scaled gradients.\n",
    "                # Backward passes under autocast are not recommended.\n",
    "                # Backward ops run in the same dtype autocast chose for corresponding forward ops.\n",
    "                scaler.scale(physical_loss).backward()\n",
    "\n",
    "                # for reporting\n",
    "                logical_train_loss += (physical_loss.detach().item())\n",
    "                token_processed += (physical_training_batch_size_per_worker * block_size)\n",
    "\n",
    "            # Unscales the gradients of optimizer's assigned parameters in-place for clipping.\n",
    "            scaler.unscale_(optimizer)\n",
    "            norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            \n",
    "            # scaler.step() first unscales the gradients of the optimizer's assigned params.\n",
    "            # If these gradients do not contain infs or NaNs, optimizer.step() is then called,\n",
    "            # otherwise, optimizer.step() is skipped\n",
    "            scaler.step(optimizer)\n",
    "            \n",
    "            # Updates the scale for next iteration.\n",
    "            scaler.update()\n",
    "            \n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        assert logical_batch_count > 0, \"logical_batch_count must be greater than 0\"\n",
    "\n",
    "        logical_train_loss = logical_train_loss / logical_batch_count\n",
    "        report_metrics[\"logical_train_loss\"] = logical_train_loss\n",
    "        report_metrics[\"logical_batch_count\"] = logical_batch_count\n",
    "\n",
    "        t1 = time.time()\n",
    "        dt = t1 - t0\n",
    "\n",
    "        token_per_second = token_processed / dt\n",
    "\n",
    "        \n",
    "        report_metrics[\"token_total\"] = token_processed\n",
    "        report_metrics[\"token_process_time_ms\"] = dt * 1000\n",
    "        report_metrics[\"token_per_second\"] = token_per_second\n",
    "\n",
    "        report_metrics[\"norm\"] = norm.item()\n",
    "\n",
    "        # Evaluate the model on the validation set only if the check_frequency is met \n",
    "        # and the current worker is the rank 0 worker\n",
    "        if epoch % check_frequency == 0 and ray.train.get_context().get_world_rank() == 0:\n",
    "            validate_loss = 0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                validate_batch_count = 0\n",
    "                for batch in validate_data_shard.iter_torch_batches(batch_size=physical_validate_batch_size_per_worker,drop_last=False,):\n",
    "                    validate_batch_count += 1\n",
    "                    input_ids = batch[\"input_ids\"]\n",
    "                    target_ids = batch[\"target_ids\"]\n",
    "\n",
    "                    with torch.autocast(device_type=device.type,dtype=floating_point_precision,enabled=use_amp,):\n",
    "                        logits = model(input_ids)\n",
    "                        loss = loss_function(logits.flatten(0, 1), target_ids.flatten())\n",
    "\n",
    "                    validate_loss += loss.item()  # only for reporting\n",
    "                    metric.update(logits, target_ids)\n",
    "\n",
    "            validate_loss = validate_loss / validate_batch_count\n",
    "            perplexity = metric.compute().item()\n",
    "            metric.reset()\n",
    "\n",
    "            report_metrics[\"validate_loss\"] = validate_loss\n",
    "            report_metrics[\"perplexity\"] = perplexity\n",
    "\n",
    "            if perplexity < best_perplexity:\n",
    "                best_perplexity = perplexity\n",
    "                best_epoch = epoch\n",
    "\n",
    "                report_metrics[\"best_epoch\"] = best_epoch\n",
    "                report_metrics[\"best_perplexity\"] = best_perplexity\n",
    "\n",
    "                # In standard DDP training, where the model is the same across all ranks,\n",
    "                # so only the global rank 0 worker needs to save and report the checkpoint\n",
    "                \n",
    "                # create the best_checkpoint_dir if it does not exist\n",
    "                if not os.path.exists(best_checkpoint_dir):\n",
    "                    os.makedirs(best_checkpoint_dir)\n",
    "\n",
    "                save_checkpoint(\n",
    "                    model,\n",
    "                    optimizer,\n",
    "                    scaler,\n",
    "                    epoch,\n",
    "                    perplexity,\n",
    "                    best_checkpoint_dir,\n",
    "                )\n",
    "\n",
    "        ray.train.report(metrics=report_metrics)\n",
    "\n",
    "        # Create a TextGenerator instance\n",
    "        # start_context = \"To be or not to be\"\n",
    "        # text_generator = TextGenerator(model, device =ray.train.torch.get_device())\n",
    "        # encoded_tensor = tokenizer.encode(start_context)\n",
    "        \n",
    "        # # Generate new text\n",
    "        # decoded = text_generator(encoded_tensor, max_new_tokens=50, block_size=1024)\n",
    "\n",
    "        # print(f\"\\n epoch-{epoch}:{decoded}\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loop_config = {\n",
    "    \"vocab_size\": cfg[\"124M\"][\"vocab_size\"],\n",
    "    \"dimension_embedding\": cfg[\"124M\"][\"dimension_embedding\"],\n",
    "    \"block_size\": cfg[\"124M\"][\"block_size\"],\n",
    "    \"num_layers\": cfg[\"124M\"][\"num_layers\"],\n",
    "    \"num_headers\": cfg[\"124M\"][\"num_headers\"],\n",
    "    \"drop_rate\": cfg[\"124M\"][\"drop_rate\"],\n",
    "    \"bias\": cfg[\"124M\"][\"bias\"],\n",
    "    \"check_frequency\": cfg[\"ray_train\"][\"check_frequency\"],\n",
    "    \"physical_training_batch_size_per_worker\": cfg[\"ray_train\"][\n",
    "        \"physical_training_batch_size_per_worker\"\n",
    "    ],\n",
    "    \"physical_validate_batch_size_per_worker\": cfg[\"ray_train\"][\n",
    "        \"physical_validate_batch_size_per_worker\"\n",
    "    ],\n",
    "    \"num_epoch_per_worker\": cfg[\"ray_train\"][\"num_epoch_per_worker\"],\n",
    "    \"resume_training\": cfg[\"ray_train\"][\"resume_training\"],\n",
    "    \"best_checkpoint_dir\": cfg[\"ray_train\"][\"best_checkpoint_dir\"],\n",
    "    \"start_context\": cfg[\"ray_train\"][\"start_context\"],\n",
    "    \"warmup_steps\": cfg[\"ray_train\"][\"warmup_steps\"],\n",
    "    \"max_steps\": cfg[\"ray_train\"][\"max_steps\"],\n",
    "    \"max_lr\": cfg[\"ray_train\"][\"max_lr\"],\n",
    "    \"min_lr\": cfg[\"ray_train\"][\"min_lr\"],\n",
    "    \"beta1\": cfg[\"ray_train\"][\"beta1\"],\n",
    "    \"beta2\": cfg[\"ray_train\"][\"beta2\"],\n",
    "    \"decay_lr\": cfg[\"ray_train\"][\"decay_lr\"],\n",
    "    \"weight_decay\": cfg[\"ray_train\"][\"weight_decay\"],\n",
    "    \"total_tokens_per_logical_batch_per_worker\": cfg[\"ray_train\"][\n",
    "        \"total_tokens_per_logical_batch_per_worker\"\n",
    "    ],\n",
    "    \"data_type\": cfg[\"ray_train\"][\"data_type\"],\n",
    "}\n",
    "\n",
    "dataset = cfg[\"dataset\"]\n",
    "block_size = cfg[\"124M\"][\"block_size\"]\n",
    "stride = cfg[\"124M\"][\"stride\"]\n",
    "\n",
    "train_chunked_tokens, validate_chunked_tokens = (\n",
    "    train_chunked_tokens,\n",
    "    validate_chunked_tokens,\n",
    ")\n",
    "\n",
    "trainer = ray.train.torch.TorchTrainer(\n",
    "    train_loop_per_worker=train_workload_per_worker,\n",
    "    train_loop_config=train_loop_config,\n",
    "    datasets={\n",
    "        \"train\": train_chunked_tokens,\n",
    "        \"validate\": validate_chunked_tokens,\n",
    "    },\n",
    "    dataset_config=ray.train.DataConfig(\n",
    "        datasets_to_split=[\"train\"],  # only split the train dataset into shards\n",
    "    ),\n",
    "    scaling_config=ray.train.ScalingConfig(\n",
    "        num_workers=cfg[\"ray_train\"][\"num_workers\"],\n",
    "        use_gpu=cfg[\"ray_train\"][\"use_gpu\"],\n",
    "        resources_per_worker={\n",
    "            \"CPU\": cfg[\"ray_train\"][\"num_cpus_per_worker\"],\n",
    "            \"GPU\": cfg[\"ray_train\"][\"num_gpus_per_worker\"],\n",
    "        },\n",
    "    ),\n",
    "    run_config=ray.train.RunConfig(\n",
    "        storage_path=cfg[\"ray_train\"][\"storage_path\"],\n",
    "        name=cfg[\"ray_train\"][\"name\"],\n",
    "    ),\n",
    ")\n",
    "result = trainer.fit()\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
