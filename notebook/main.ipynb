{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "project_root = os.path.dirname(os.getcwd())\n",
    "sys.path.append(f\"{project_root}/src\")\n",
    "sys.path.append(f\"{project_root}/third_party\")\n",
    "\n",
    "from config import gpt2_cfg as cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 12:03:43,571\tWARNING services.py:2017 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=8.30gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2024-07-29 12:03:43,685\tINFO worker.py:1781 -- Started a local Ray instance.\n",
      "2024-07-29 12:03:43,690\tINFO packaging.py:530 -- Creating a file package for local directory '/workspaces/CaiZi'.\n",
      "2024-07-29 12:03:43,695\tINFO packaging.py:358 -- Pushing file package 'gcs://_ray_pkg_8d1dfbd98c4afcca.zip' (0.28MiB) to Ray cluster...\n",
      "2024-07-29 12:03:43,696\tINFO packaging.py:371 -- Successfully pushed file package 'gcs://_ray_pkg_8d1dfbd98c4afcca.zip'.\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "if not ray.is_initialized():\n",
    "    ray.init(\n",
    "        runtime_env={\n",
    "            \"env_vars\": {          \n",
    "                \"PYTHONPATH\": \"$PYTHONPATH:\" + cfg.project_root + \"/src\",\n",
    "            },\n",
    "            \"working_dir\": cfg.project_root,\n",
    "            \"excludes\": [\n",
    "                \"/bazel-*\",\n",
    "                \".git\",\n",
    "                \"*.pyc\",\n",
    "                \"/__pycache__\",\n",
    "                \"/output\",\n",
    "                \"/model\",\n",
    "            ],\n",
    "           \n",
    "        },\n",
    "        _metrics_export_port=8080,\n",
    "    )\n",
    "# convience for debugging\n",
    "ray.data.DataContext.get_current().execution_options.verbose_progress = True\n",
    "ray.data.DataContext.log_internal_stack_trace_to_stdout = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "data_sources = [ Path(item[\"path\"]) for item in cfg[\"dataset\"]]\n",
    "text_document_paths = ray.data.from_items(data_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from document_processor import TextDocumentProcessor\n",
    "text_document_processor = TextDocumentProcessor()\n",
    "texts=text_document_paths.map(text_document_processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from token_processor import TikTokenizer\n",
    "tokenizer = TikTokenizer()\n",
    "tokens = texts.map(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chunk_processor import ChunkProcessor\n",
    "chunk_processor = ChunkProcessor()\n",
    "chunked_tokens = tokens.flat_map(chunk_processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in chunked_tokens.iter_torch_batches(batch_size=cfg.batch_size):\n",
    "    print(batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
