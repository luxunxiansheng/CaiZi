{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "project_root = os.path.dirname(os.getcwd())\n",
    "sys.path.append(f\"{project_root}/src\")\n",
    "sys.path.append(f\"{project_root}/third_party\")\n",
    "\n",
    "os.environ[\"RAY_DEDUP_LOGS\"] = \"0\"\n",
    "os.environ[\"RAY_COLOR_PREFIX\"] = \"0\"\n",
    "\n",
    "from config import gpt2_cfg as cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-06 02:10:05,360\tINFO worker.py:1772 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "2024-08-06 02:10:05,369\tINFO packaging.py:530 -- Creating a file package for local directory '/workspaces/CaiZi'.\n",
      "2024-08-06 02:10:05,377\tINFO packaging.py:358 -- Pushing file package 'gcs://_ray_pkg_f2a5e622f932d600.zip' (1.41MiB) to Ray cluster...\n",
      "2024-08-06 02:10:05,385\tINFO packaging.py:371 -- Successfully pushed file package 'gcs://_ray_pkg_f2a5e622f932d600.zip'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=171354) [rank0]:[W806 02:14:16.158049364 ProcessGroupNCCL.cpp:1168] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "if ray.is_initialized():\n",
    "    ray.shutdown()\n",
    "\n",
    "ray.init(\n",
    "        runtime_env={\n",
    "            \"env_vars\": {          \n",
    "                \"PYTHONPATH\": \"$PYTHONPATH:\" + cfg.project_root + \"/src\",\n",
    "                \"RAY_DATA_VERBOSE_PROGRESS\": \"1\",\n",
    "            },\n",
    "            \"working_dir\": cfg.project_root,\n",
    "            \"excludes\": [\n",
    "                \"/bazel-*\",\n",
    "                \".git\",\n",
    "                \"*.pyc\",\n",
    "                \"/__pycache__\",\n",
    "                \"/outputs\",\n",
    "                \"/model\",\n",
    "            ],\n",
    "        },\n",
    "        ignore_reinit_error=True,\n",
    "    )\n",
    "\n",
    "# convience for debugging\n",
    "ray.data.DataContext.get_current().execution_options.verbose_progress = False\n",
    "ray.data.DataContext.log_internal_stack_trace_to_stdout = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "data_sources = [ Path(item[\"path\"]) for item in cfg[\"dataset\"]]\n",
    "text_document_paths = ray.data.from_items(data_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from document_processor import TextDocumentProcessor\n",
    "train_text_document_processor = TextDocumentProcessor(section=\"train\")\n",
    "train_texts=text_document_paths.map(train_text_document_processor)\n",
    "\n",
    "validate_text_document_processor = TextDocumentProcessor(section=\"validate\")\n",
    "validate_texts=text_document_paths.map(validate_text_document_processor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from token_processor import TikTokenizer\n",
    "tokenizer = TikTokenizer()\n",
    "train_tokens = train_texts.map(tokenizer)\n",
    "validate_tokens = validate_texts.map(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chunk_processor import ChunkProcessor\n",
    "\n",
    "chunk_processor = ChunkProcessor(max_length=cfg[\"124M\"][\"block_size\"],stride=cfg[\"124M\"][\"stride\"])\n",
    "train_chunked_tokens = train_tokens.flat_map(chunk_processor)\n",
    "validate_chunked_tokens = validate_tokens.flat_map(chunk_processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-06 02:10:08.031308: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-06 02:10:08.039493: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-06 02:10:08.048390: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-06 02:10:08.051096: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-06 02:10:08.058914: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-06 02:10:08.470015: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchmetrics.text import Perplexity\n",
    "\n",
    "import ray\n",
    "import ray.train\n",
    "\n",
    "from model.GPT import GPT\n",
    "from utility import save_checkpoint, resume_checkpoint\n",
    "from text_generator import TextGenerator\n",
    "\n",
    "\n",
    "def train_loop_per_worker(config):\n",
    "    vocab_size = config[\"vocab_size\"]\n",
    "    dimension_embedding = config[\"dimension_embedding\"]\n",
    "    block_size = config[\"block_size\"]\n",
    "    num_layers = config[\"num_layers\"]\n",
    "    num_headers = config[\"num_headers\"]\n",
    "    drop_rate = config[\"drop_rate\"]\n",
    "    qkv_bias = config[\"qkv_bias\"]\n",
    "    check_frequency = config[\"check_frequency\"]\n",
    "    batch_size_per_worker = config[\"batch_size_per_worker\"]\n",
    "    num_epoch_per_worker = config[\"num_epoch_per_worker\"]\n",
    "    resume_training = config[\"resume_training\"]\n",
    "    best_checkpoint_dir = config[\"best_checkpoint_dir\"]\n",
    "    start_context = config[\"start_context\"]\n",
    "\n",
    "    # GPT model\n",
    "    model = GPT(\n",
    "        vocab_size,\n",
    "        dimension_embedding,\n",
    "        block_size,\n",
    "        num_layers,\n",
    "        num_headers,\n",
    "        drop_rate,\n",
    "        qkv_bias,\n",
    "    )\n",
    "    model = ray.train.torch.prepare_model(model)\n",
    "\n",
    "    # optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "    # ====== Resume training state from the checkpoint. ======\n",
    "    epoch_start = 0\n",
    "    best_perplexity = 1000000.0\n",
    "    best_epoch = 0\n",
    "\n",
    "    if resume_training:\n",
    "        if os.path.exists(best_checkpoint_dir):\n",
    "            checkpoint = ray.train.Checkpoint.from_directory(best_checkpoint_dir)\n",
    "        else:\n",
    "            checkpoint = None\n",
    "        if checkpoint:\n",
    "            best_epoch, best_perplexity = resume_checkpoint(model, optimizer, checkpoint)\n",
    "            epoch_start = best_epoch\n",
    "            print(\n",
    "                f\"Resumed training from best_epoch {best_epoch},best_perplexity {best_perplexity}\"\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Checkpoint not found, starting from epoch 0\")\n",
    "\n",
    "    # loss function\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    rank = ray.train.get_context().get_world_rank()\n",
    "    device = torch.device(f\"cuda:{rank}\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # metrics\n",
    "    metric = Perplexity().to(device)\n",
    "\n",
    "    # data\n",
    "    train_data_shard = ray.train.get_dataset_shard(\"train\")\n",
    "    validate_data_shard = ray.train.get_dataset_shard(\"validate\")\n",
    "\n",
    "    report_metrics = {\n",
    "        \"epoch\": 0,\n",
    "        \"train_loss\": 0.0,\n",
    "        \"validate_loss\": 0.0,\n",
    "        \"perplexity\": 0.0,\n",
    "        \"best_epoch\": best_epoch,\n",
    "        \"best_perplexity\": best_perplexity,\n",
    "    }\n",
    " \n",
    " \n",
    "    text_generator = TextGenerator(model,device=device)\n",
    "    tokenizer = TikTokenizer()\n",
    "    for epoch in range(epoch_start + 1, num_epoch_per_worker + 1):\n",
    "        model.train()\n",
    "\n",
    "        report_metrics[\"epoch\"] = epoch\n",
    "\n",
    "        train_loss = 0\n",
    "        batch_count = 0\n",
    "        for batch in train_data_shard.iter_torch_batches(\n",
    "            batch_size=batch_size_per_worker,\n",
    "            drop_last=True,\n",
    "            local_shuffle_buffer_size=1000,\n",
    "        ):\n",
    "            batch_count += 1\n",
    "            input_ids = batch[\"input_ids\"]\n",
    "            logits = model(input_ids)\n",
    "            target_ids = batch[\"target_ids\"]\n",
    "            loss = loss_function(logits.flatten(0, 1), target_ids.flatten())\n",
    "            train_loss += loss.item()  # only for reporting\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss = train_loss / batch_count\n",
    "\n",
    "        report_metrics[\"train_loss\"] = train_loss\n",
    "\n",
    "        validate_loss = 0\n",
    "        perplexity = 0\n",
    "\n",
    "        if epoch % check_frequency == 0:\n",
    "\n",
    "            model.eval()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                batch_count = 0\n",
    "                for batch in validate_data_shard.iter_torch_batches(\n",
    "                    batch_size=1,\n",
    "                    drop_last=False,\n",
    "                ):\n",
    "                    batch_count += 1\n",
    "                    input_ids = batch[\"input_ids\"]\n",
    "                    logits = model(input_ids)\n",
    "                    target_ids = batch[\"target_ids\"]\n",
    "                    loss = loss_function(logits.flatten(0, 1), target_ids.flatten())\n",
    "                    validate_loss += loss.item()  # only for reporting\n",
    "                    metric.update(logits, target_ids)\n",
    "\n",
    "            validate_loss = validate_loss / batch_count\n",
    "            perplexity = metric.compute().item()\n",
    "            metric.reset()\n",
    "\n",
    "            report_metrics[\"validate_loss\"] = validate_loss\n",
    "            report_metrics[\"perplexity\"] = perplexity\n",
    "\n",
    "\n",
    "            # In standard DDP training, where the model is the same across all ranks,\n",
    "            # only the global rank 0 worker needs to save and report the checkpoint\n",
    "            if ray.train.get_context().get_world_rank() == 0:\n",
    "                if perplexity < best_perplexity:\n",
    "                    best_perplexity = perplexity\n",
    "                    best_epoch = epoch\n",
    "                    \n",
    "                    report_metrics[\"best_epoch\"] = best_epoch\n",
    "                    report_metrics[\"best_perplexity\"] = best_perplexity\n",
    "\n",
    "\n",
    "                    # create the best_checkpoint_dir if it does not exist\n",
    "                    if not os.path.exists(best_checkpoint_dir):\n",
    "                        os.makedirs(best_checkpoint_dir)\n",
    "\n",
    "                    save_checkpoint(\n",
    "                        model,\n",
    "                        optimizer,\n",
    "                        epoch,\n",
    "                        perplexity,\n",
    "                        best_checkpoint_dir,\n",
    "                    )\n",
    "\n",
    "                ray.train.report(metrics=report_metrics)\n",
    "                \n",
    "        decoded = text_generator(tokenizer.encode(start_context), max_new_tokens=50, context_size=block_size)\n",
    "        print(f\"\\n epoch{epoch}:{decoded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-06 02:10:09,249\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-08-06 02:10:09 (running for 00:00:00.11)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 02:10:14 (running for 00:00:05.17)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(TrainTrainable pid=170994) 2024-08-06 02:10:11.792528: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "(TrainTrainable pid=170994) 2024-08-06 02:10:11.800061: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "(TrainTrainable pid=170994) 2024-08-06 02:10:11.808508: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "(TrainTrainable pid=170994) 2024-08-06 02:10:11.811122: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "(TrainTrainable pid=170994) 2024-08-06 02:10:11.818122: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "(TrainTrainable pid=170994) To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "(TrainTrainable pid=170994) 2024-08-06 02:10:12.311202: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "(TorchTrainer pid=170994) Started distributed worker processes: \n",
      "(TorchTrainer pid=170994) - (node_id=f3a57e1839b218fae90a807d19a0c7fc120605349056206b9233739b, ip=172.17.0.2, pid=171354) world_rank=0, local_rank=0, node_rank=0\n",
      "(RayTrainWorker pid=171354) Setting up process group for: env:// [rank=0, world_size=1]\n",
      "(RayTrainWorker pid=171354) [W806 02:10:14.695860838 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())\n",
      "(RayTrainWorker pid=171354) 2024-08-06 02:10:14.639539: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "(RayTrainWorker pid=171354) 2024-08-06 02:10:14.647413: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "(RayTrainWorker pid=171354) 2024-08-06 02:10:14.656559: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "(RayTrainWorker pid=171354) 2024-08-06 02:10:14.659334: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "(RayTrainWorker pid=171354) 2024-08-06 02:10:14.666480: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "(RayTrainWorker pid=171354) To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "(RayTrainWorker pid=171354) 2024-08-06 02:10:15.112940: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "(RayTrainWorker pid=171354) Moving model to device: cuda:0\n",
      "(SplitCoordinator pid=171436) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-06_02-10-04_641366_168577/logs/ray-data\n",
      "(SplitCoordinator pid=171436) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n",
      "(SplitCoordinator pid=171437) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-06_02-10-04_641366_168577/logs/ray-data\n",
      "(SplitCoordinator pid=171437) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01595a318c6f42a88cf5b4a3479da484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=171436) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-08-06 02:10:19 (running for 00:00:10.18)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 02:10:24 (running for 00:00:15.19)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa7a46941acd40b8aa3de5a15f82ff22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=171437) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-08-06 02:10:29 (running for 00:00:20.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 02:10:34 (running for 00:00:25.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354)  epoch1:Every effort moves you,\n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55be7e1271ab4b2880b11bb0a8843739",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=171436) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(SplitCoordinator pid=171436) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-06_02-10-04_641366_168577/logs/ray-data\n",
      "(SplitCoordinator pid=171436) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n",
      "(SplitCoordinator pid=171437) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-06_02-10-04_641366_168577/logs/ray-data\n",
      "(SplitCoordinator pid=171437) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-08-06 02:10:39 (running for 00:00:30.21)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "048165807f3549fe85d1a8aefef860ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=171437) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-08-06 02:10:44 (running for 00:00:35.22)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 02:10:49 (running for 00:00:40.24)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354)  epoch2:Every effort moves you,\n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb2c4d4518c049e0b8ca6f7e17f502b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=171436) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(SplitCoordinator pid=171436) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-06_02-10-04_641366_168577/logs/ray-data\n",
      "(SplitCoordinator pid=171436) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n",
      "(SplitCoordinator pid=171437) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-06_02-10-04_641366_168577/logs/ray-data\n",
      "(SplitCoordinator pid=171437) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-08-06 02:10:54 (running for 00:00:45.24)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 02:10:59 (running for 00:00:50.25)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a4aa8aac7cf45468792d8e14ee3c33e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=171437) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-08-06 02:11:04 (running for 00:00:55.27)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354)  epoch3:Every effort moves you,\n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b45afa9cb2ee4e3fb4ade82c22237229",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=171436) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(SplitCoordinator pid=171436) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-06_02-10-04_641366_168577/logs/ray-data\n",
      "(SplitCoordinator pid=171436) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n",
      "(SplitCoordinator pid=171437) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-06_02-10-04_641366_168577/logs/ray-data\n",
      "(SplitCoordinator pid=171437) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-08-06 02:11:09 (running for 00:01:00.29)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 02:11:14 (running for 00:01:05.30)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73aceee137e347fdbd6e77e58e50d22c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=171437) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-08-06 02:11:19 (running for 00:01:10.32)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354)  epoch4:Every effort moves you,\n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fac2c02ce38c4879865775e84f3ab3e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=171436) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(SplitCoordinator pid=171436) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-06_02-10-04_641366_168577/logs/ray-data\n",
      "(SplitCoordinator pid=171436) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n",
      "(SplitCoordinator pid=171437) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-06_02-10-04_641366_168577/logs/ray-data\n",
      "(SplitCoordinator pid=171437) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-08-06 02:11:24 (running for 00:01:15.35)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 02:11:29 (running for 00:01:20.37)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f77e254d4864fdbb87b149687ead922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=171437) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-08-06 02:11:34 (running for 00:01:25.37)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354)  epoch5:Every effort moves you,\n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) And,\n",
      "(RayTrainWorker pid=171354) And I'll not,\n",
      "(RayTrainWorker pid=171354) And,\n",
      "(RayTrainWorker pid=171354) And I,\n",
      "(RayTrainWorker pid=171354) And,\n",
      "(RayTrainWorker pid=171354) And,\n",
      "(RayTrainWorker pid=171354) And,\n",
      "(RayTrainWorker pid=171354) And,\n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) And,\n",
      "(RayTrainWorker pid=171354) And,\n",
      "(RayTrainWorker pid=171354) And,\n",
      "(RayTrainWorker pid=171354) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ffcf3ee13034160b0b5d7d0c2c7db4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=171436) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-08-06 02:11:39 (running for 00:01:30.46)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 02:11:44 (running for 00:01:35.47)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(SplitCoordinator pid=171436) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-06_02-10-04_641366_168577/logs/ray-data\n",
      "(SplitCoordinator pid=171436) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n",
      "(SplitCoordinator pid=171437) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-06_02-10-04_641366_168577/logs/ray-data\n",
      "(SplitCoordinator pid=171437) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6302f98fa8840b2bedb5d2e00e7e72b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=171437) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-08-06 02:11:49 (running for 00:01:40.48)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354)  epoch6:Every effort moves you have heard\n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c275abd8d04c450d884558d1d6ad38d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=171436) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(SplitCoordinator pid=171436) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-06_02-10-04_641366_168577/logs/ray-data\n",
      "(SplitCoordinator pid=171436) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n",
      "(SplitCoordinator pid=171437) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-06_02-10-04_641366_168577/logs/ray-data\n",
      "(SplitCoordinator pid=171437) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-08-06 02:11:54 (running for 00:01:45.48)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 02:11:59 (running for 00:01:50.49)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b850de82cd7403d9519bf1121f5376f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=171437) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354)  epoch7:Every effort moves you have heard\n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3bcf925712d4921bfd484da9f82a35f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=171436) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(SplitCoordinator pid=171436) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-06_02-10-04_641366_168577/logs/ray-data\n",
      "(SplitCoordinator pid=171436) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n",
      "(SplitCoordinator pid=171437) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-06_02-10-04_641366_168577/logs/ray-data\n",
      "(SplitCoordinator pid=171437) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-08-06 02:12:04 (running for 00:01:55.52)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 02:12:09 (running for 00:02:00.53)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6c63162f35246aead48eb60e87864e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=171437) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354)  epoch8:Every effort moves you that,\n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) And so much\n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) And that the or your queen,\n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) And so your brother,\n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) For me\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b306abd1d98484c948cd75d2facee7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=171436) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(SplitCoordinator pid=171436) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-06_02-10-04_641366_168577/logs/ray-data\n",
      "(SplitCoordinator pid=171436) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n",
      "(SplitCoordinator pid=171437) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-06_02-10-04_641366_168577/logs/ray-data\n",
      "(SplitCoordinator pid=171437) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-08-06 02:12:14 (running for 00:02:05.58)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 02:12:19 (running for 00:02:10.59)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0376abd0861a4436a76564b738e444e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=171437) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354)  epoch9:Every effort moves you\n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ce2ffef28dc4553aa2c56cc4b730e08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=171436) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(SplitCoordinator pid=171436) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-06_02-10-04_641366_168577/logs/ray-data\n",
      "(SplitCoordinator pid=171436) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n",
      "(SplitCoordinator pid=171437) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-06_02-10-04_641366_168577/logs/ray-data\n",
      "(SplitCoordinator pid=171437) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-08-06 02:12:24 (running for 00:02:15.65)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 02:12:29 (running for 00:02:20.66)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8ae48114a7a4f61a00e4ea724e27116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=171437) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354)  epoch10:Every effort moves you,\n",
      "(RayTrainWorker pid=171354) The people,\n",
      "(RayTrainWorker pid=171354) Which you will,\n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) And this in your my state I stay'd the king's face.\n",
      "(RayTrainWorker pid=171354) And yet I must die than to be so young,\n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) The blood:\n",
      "(RayTrainWorker pid=171354) And every mess of death\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "573c99562a46461aa49c51eb7f616c3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=171436) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(SplitCoordinator pid=171436) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-06_02-10-04_641366_168577/logs/ray-data\n",
      "(SplitCoordinator pid=171436) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n",
      "(SplitCoordinator pid=171437) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-06_02-10-04_641366_168577/logs/ray-data\n",
      "(SplitCoordinator pid=171437) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-08-06 02:12:34 (running for 00:02:25.73)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 02:12:40 (running for 00:02:30.74)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69e1bb075e164d6b864c6882432c1c0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=171437) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354)  epoch11:Every effort moves you play it is meet so much more.\n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) What my lord! why,\n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) Nurse!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88c1bceb838a4e45b3cf8727a7988ff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=171436) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(SplitCoordinator pid=171436) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-06_02-10-04_641366_168577/logs/ray-data\n",
      "(SplitCoordinator pid=171436) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n",
      "(SplitCoordinator pid=171437) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-06_02-10-04_641366_168577/logs/ray-data\n",
      "(SplitCoordinator pid=171437) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-08-06 02:12:45 (running for 00:02:35.80)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 02:12:50 (running for 00:02:40.81)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "226fcfe7b2274451b5ed988bf83c8078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=171437) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354)  epoch12:Every effort moves you will keep her father:\n",
      "(RayTrainWorker pid=171354) Which you love me.\n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) I am too old to say that I have worn a constant temper.\n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) Do as they lie asleep;\n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) Both disobedience and ingratitude\n",
      "(RayTrainWorker pid=171354) To\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aff994a11394783a2ac683a4bb732ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=171436) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(SplitCoordinator pid=171436) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-06_02-10-04_641366_168577/logs/ray-data\n",
      "(SplitCoordinator pid=171436) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n",
      "(SplitCoordinator pid=171437) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-06_02-10-04_641366_168577/logs/ray-data\n",
      "(SplitCoordinator pid=171437) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-08-06 02:12:55 (running for 00:02:45.89)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 02:13:00 (running for 00:02:50.90)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76e8766c00124aa28baaced08130267a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=171437) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354)  epoch13:Every effort moves you, we should have none\n",
      "(RayTrainWorker pid=171354) shortly, for one would kill the other. Thou! why,\n",
      "(RayTrainWorker pid=171354) thou wilt quarrel with a man that hath a hair more,\n",
      "(RayTrainWorker pid=171354) or a hair less, in his beard, than thou hast: thou\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a95752f475b42a7aaaa0ceb82f82e24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=171436) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(SplitCoordinator pid=171436) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-06_02-10-04_641366_168577/logs/ray-data\n",
      "(SplitCoordinator pid=171436) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n",
      "(SplitCoordinator pid=171437) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-06_02-10-04_641366_168577/logs/ray-data\n",
      "(SplitCoordinator pid=171437) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-08-06 02:13:05 (running for 00:02:55.95)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 02:13:10 (running for 00:03:00.96)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ed8d7efe75e4b0da3fc17b6b17e0c76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=171437) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354)  epoch14:Every effort moves you,\n",
      "(RayTrainWorker pid=171354) The people\n",
      "(RayTrainWorker pid=171354) Like one\n",
      "(RayTrainWorker pid=171354) Thou shalt not here big for the lightning,\n",
      "(RayTrainWorker pid=171354) Than dangerous to me;\n",
      "(RayTrainWorker pid=171354) You are to Plashy too;\n",
      "(RayTrainWorker pid=171354) I thank thee and my name\n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) I now go toward him;\n",
      "(RayTrainWorker pid=171354) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a56314af95b4350a7c92b0683f81a4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=171436) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(SplitCoordinator pid=171436) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-06_02-10-04_641366_168577/logs/ray-data\n",
      "(SplitCoordinator pid=171436) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n",
      "(SplitCoordinator pid=171437) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-06_02-10-04_641366_168577/logs/ray-data\n",
      "(SplitCoordinator pid=171437) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-08-06 02:13:15 (running for 00:03:06.04)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 02:13:20 (running for 00:03:11.05)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22dc26f37f4e437e92ceade263293a7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=171437) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354)  epoch15:Every effort moves you live to your bands:\n",
      "(RayTrainWorker pid=171354) Which you love me.\n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) And your men,\n",
      "(RayTrainWorker pid=171354) QUEEN ELIZABETH:\n",
      "(RayTrainWorker pid=171354) No less! rather see thee here\n",
      "(RayTrainWorker pid=171354) And then came I can yield my young cousin,\n",
      "(RayTrainWorker pid=171354) I amiss of\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c0a8b074db1496ca4b4915a01131a09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=171436) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(SplitCoordinator pid=171436) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-06_02-10-04_641366_168577/logs/ray-data\n",
      "(SplitCoordinator pid=171436) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n",
      "(SplitCoordinator pid=171437) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-06_02-10-04_641366_168577/logs/ray-data\n",
      "(SplitCoordinator pid=171437) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-08-06 02:13:25 (running for 00:03:16.06)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 02:13:30 (running for 00:03:21.07)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3708ae1d1850493495409a9dfeb322ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=171437) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354)  epoch16:Every effort moves you gave leave to my unwilling tongue\n",
      "(RayTrainWorker pid=171354) Against my will to do myself this wrong.\n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) KING RICHARD II:\n",
      "(RayTrainWorker pid=171354) Cousin, farewell; and, uncle, bid him so:\n",
      "(RayTrainWorker pid=171354) Six years we banish him, and he shall\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f0419ec2f7f43ef978bf85d0b71bf7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=171436) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(SplitCoordinator pid=171436) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-06_02-10-04_641366_168577/logs/ray-data\n",
      "(SplitCoordinator pid=171436) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n",
      "(SplitCoordinator pid=171437) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-06_02-10-04_641366_168577/logs/ray-data\n",
      "(SplitCoordinator pid=171437) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-08-06 02:13:35 (running for 00:03:26.08)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 02:13:40 (running for 00:03:31.09)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf0dbfa109b4ef3a9c341f386d6cd10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=171437) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354)  epoch17:Every effort moves you gave leave to my unwilling tongue\n",
      "(RayTrainWorker pid=171354) Against my will to do myself this wrong.\n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) KING RICHARD II:\n",
      "(RayTrainWorker pid=171354) Cousin, farewell; and, uncle, bid him so:\n",
      "(RayTrainWorker pid=171354) Six years we banish him, and he shall\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f3ac30d52cf4544b2817acdba134a04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=171436) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(SplitCoordinator pid=171436) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-06_02-10-04_641366_168577/logs/ray-data\n",
      "(SplitCoordinator pid=171436) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n",
      "(SplitCoordinator pid=171437) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-06_02-10-04_641366_168577/logs/ray-data\n",
      "(SplitCoordinator pid=171437) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-08-06 02:13:45 (running for 00:03:36.18)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 02:13:50 (running for 00:03:41.19)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "309edb292077467b81ad4b9dfdf16491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=171437) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354)  epoch18:Every effort moves you gave leave to my unwilling tongue\n",
      "(RayTrainWorker pid=171354) Against my will to do myself this wrong.\n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) KING RICHARD II:\n",
      "(RayTrainWorker pid=171354) Cousin, farewell; and, uncle, bid him so:\n",
      "(RayTrainWorker pid=171354) Six years we banish him, and he shall\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8d8e6e466c847e89cfec25f15563562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=171436) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(SplitCoordinator pid=171436) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-06_02-10-04_641366_168577/logs/ray-data\n",
      "(SplitCoordinator pid=171436) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n",
      "(SplitCoordinator pid=171437) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-06_02-10-04_641366_168577/logs/ray-data\n",
      "(SplitCoordinator pid=171437) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-08-06 02:13:55 (running for 00:03:46.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 02:14:00 (running for 00:03:51.21)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45983540f7254942bc5eb0f9821384d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=171437) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354)  epoch19:Every effort moves you fear?\n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) Against the lords you talk of are beheaded.\n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) LORD STANUS:\n",
      "(RayTrainWorker pid=171354) I brought my tent, and I,\n",
      "(RayTrainWorker pid=171354) And,\n",
      "(RayTrainWorker pid=171354) I mean the cause,\n",
      "(RayTrainWorker pid=171354) But, for you:\n",
      "(RayTrainWorker pid=171354) But come\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f961bbdc76d44ca5b094dbdd67b95b74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=171436) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(SplitCoordinator pid=171436) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-06_02-10-04_641366_168577/logs/ray-data\n",
      "(SplitCoordinator pid=171436) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n",
      "(SplitCoordinator pid=171437) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-06_02-10-04_641366_168577/logs/ray-data\n",
      "(SplitCoordinator pid=171437) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-08-06 02:14:05 (running for 00:03:56.21)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 02:14:10 (running for 00:04:01.22)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff9478af0f5049a1a4afd7c0c05f900a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=171437) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354)  epoch20:Every effort moves you fear?\n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) Against the lords you talk of are beheaded.\n",
      "(RayTrainWorker pid=171354) \n",
      "(RayTrainWorker pid=171354) LORD STANUS:\n",
      "(RayTrainWorker pid=171354) I hope he, sir, might better wear their heads\n",
      "(RayTrainWorker pid=171354) Were I have been in any liquid thing you will,\n",
      "(RayTrainWorker pid=171354) But come\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-08-06 02:14:15 (running for 00:04:06.24)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-06 02:14:16,483\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/workspaces/CaiZi/outputs/gpt2/124M' in 0.0019s.\n",
      "2024-08-06 02:14:16,484\tINFO tune.py:1041 -- Total run time: 247.24 seconds (247.22 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-08-06 02:14:16 (running for 00:04:07.23)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_02-10-04_641366_168577/artifacts/2024-08-06_02-10-09/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 TERMINATED)\n",
      "\n",
      "\n",
      "{'epoch': 20, 'train_loss': 0.15964282916425027, 'validate_loss': 7.7357090405055455, 'perplexity': 2288.631103515625, 'best_epoch': 5, 'best_perplexity': 149.89683532714844, 'timestamp': 1722910455, 'checkpoint_dir_name': None, 'done': True, 'training_iteration': 20, 'trial_id': '01873_00000', 'date': '2024-08-06_02-14-15', 'time_this_iter_s': 10.420353412628174, 'time_total_s': 242.34613299369812, 'pid': 170994, 'hostname': '32452cd6fad6', 'node_ip': '172.17.0.2', 'config': {'train_loop_config': {'vocab_size': 50257, 'dimension_embedding': 768, 'block_size': 1024, 'num_layers': 12, 'num_headers': 12, 'drop_rate': 0.1, 'qkv_bias': False, 'check_frequency': 1, 'batch_size_per_worker': 4, 'num_epoch_per_worker': 20, 'resume_training': False, 'best_checkpoint_dir': '/workspaces/CaiZi/model_weights/best_checkpoint', 'start_context': 'Every effort moves you'}}, 'time_since_restore': 242.34613299369812, 'iterations_since_restore': 20, 'experiment_tag': '0'}\n"
     ]
    }
   ],
   "source": [
    "from ray.train.torch import TorchTrainer\n",
    "from ray.train import Result\n",
    "from ray import train\n",
    "\n",
    "train_loop_config = {\n",
    "    \"vocab_size\": cfg[\"124M\"][\"vocab_size\"],\n",
    "    \"dimension_embedding\": cfg[\"124M\"][\"dimension_embedding\"],\n",
    "    \"block_size\": cfg[\"124M\"][\"block_size\"],\n",
    "    \"num_layers\": cfg[\"124M\"][\"num_layers\"],\n",
    "    \"num_headers\": cfg[\"124M\"][\"num_headers\"],\n",
    "    \"drop_rate\": cfg[\"124M\"][\"drop_rate\"],\n",
    "    \"qkv_bias\": cfg[\"124M\"][\"qkv_bias\"],\n",
    "    \"check_frequency\": cfg[\"ray_train\"][\"check_frequency\"],\n",
    "    \"batch_size_per_worker\": cfg[\"ray_train\"][\"batch_size_per_worker\"],\n",
    "    \"num_epoch_per_worker\": cfg[\"ray_train\"][\"num_epoch_per_worker\"],\n",
    "    \"resume_training\":cfg[\"ray_train\"][\"resume_training\"],\n",
    "    \"best_checkpoint_dir\":cfg[\"ray_train\"][\"best_checkpoint_dir\"],\n",
    "    \"start_context\":cfg[\"ray_train\"][\"start_context\"],\n",
    "}\n",
    "\n",
    "\n",
    "trainer = TorchTrainer(\n",
    "    train_loop_per_worker=train_loop_per_worker,\n",
    "    train_loop_config=train_loop_config,\n",
    "    datasets={\n",
    "        \"train\": train_chunked_tokens,\n",
    "        \"validate\": validate_chunked_tokens,\n",
    "    },\n",
    "    scaling_config=ray.train.ScalingConfig(\n",
    "        num_workers=cfg[\"ray_train\"][\"num_workers\"],\n",
    "        use_gpu=cfg[\"ray_train\"][\"use_gpu\"],\n",
    "        resources_per_worker={\n",
    "            \"CPU\": cfg[\"ray_train\"][\"num_cpus_per_worker\"],\n",
    "            \"GPU\": cfg[\"ray_train\"][\"num_gpus_per_worker\"],\n",
    "        },\n",
    "    ),\n",
    "    run_config=train.RunConfig(\n",
    "        storage_path=cfg[\"ray_train\"][\"storage_path\"],\n",
    "        name=cfg[\"ray_train\"][\"name\"],\n",
    "    ),\n",
    "    \n",
    ")\n",
    "result: Result = trainer.fit()\n",
    "print(result.metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
