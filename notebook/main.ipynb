{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "project_root = os.path.dirname(os.getcwd())\n",
    "sys.path.append(f\"{project_root}/src\")\n",
    "sys.path.append(f\"{project_root}/third_party\")\n",
    "\n",
    "os.environ[\"RAY_DEDUP_LOGS\"] = \"0\"\n",
    "os.environ[\"RAY_COLOR_PREFIX\"] = \"0\"\n",
    "\n",
    "from config import gpt2_cfg as cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-06 07:36:42,053\tWARNING services.py:2017 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 8911437824 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=10.24gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2024-08-06 07:36:43,231\tINFO worker.py:1772 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "2024-08-06 07:36:43,279\tINFO packaging.py:530 -- Creating a file package for local directory '/workspaces/CaiZi'.\n",
      "2024-08-06 07:36:43,309\tINFO packaging.py:358 -- Pushing file package 'gcs://_ray_pkg_d78a0377945c9b4a.zip' (1.41MiB) to Ray cluster...\n",
      "2024-08-06 07:36:43,341\tINFO packaging.py:371 -- Successfully pushed file package 'gcs://_ray_pkg_d78a0377945c9b4a.zip'.\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "if ray.is_initialized():\n",
    "    ray.shutdown()\n",
    "\n",
    "ray.init(\n",
    "        runtime_env={\n",
    "            \"env_vars\": {          \n",
    "                \"PYTHONPATH\": \"$PYTHONPATH:\" + cfg.project_root + \"/src\",\n",
    "                \"RAY_DATA_VERBOSE_PROGRESS\": \"1\",\n",
    "            },\n",
    "            \"working_dir\": cfg.project_root,\n",
    "            \"excludes\": [\n",
    "                \"/bazel-*\",\n",
    "                \".git\",\n",
    "                \"*.pyc\",\n",
    "                \"/__pycache__\",\n",
    "                \"/outputs\",\n",
    "                \"/model\",\n",
    "            ],\n",
    "        },\n",
    "        ignore_reinit_error=True,\n",
    "    )\n",
    "\n",
    "# convience for debugging\n",
    "ray.data.DataContext.get_current().execution_options.verbose_progress = False\n",
    "ray.data.DataContext.log_internal_stack_trace_to_stdout = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "data_sources = [ Path(item[\"path\"]) for item in cfg[\"dataset\"]]\n",
    "text_document_paths = ray.data.from_items(data_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from document_processor import TextDocumentProcessor\n",
    "train_text_document_processor = TextDocumentProcessor(section=\"train\")\n",
    "train_texts=text_document_paths.map(train_text_document_processor)\n",
    "\n",
    "validate_text_document_processor = TextDocumentProcessor(section=\"validate\")\n",
    "validate_texts=text_document_paths.map(validate_text_document_processor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from token_processor import TikTokenizer\n",
    "tokenizer = TikTokenizer()\n",
    "train_tokens = train_texts.map(tokenizer)\n",
    "validate_tokens = validate_texts.map(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chunk_processor import ChunkProcessor\n",
    "\n",
    "chunk_processor = ChunkProcessor(max_length=cfg[\"124M\"][\"block_size\"],stride=cfg[\"124M\"][\"stride\"])\n",
    "train_chunked_tokens = train_tokens.flat_map(chunk_processor)\n",
    "validate_chunked_tokens = validate_tokens.flat_map(chunk_processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-06 07:36:51.960990: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-06 07:36:51.980315: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-06 07:36:52.000752: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-06 07:36:52.006986: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-06 07:36:52.025535: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-06 07:36:53.128511: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchmetrics.text import Perplexity\n",
    "\n",
    "import ray\n",
    "import ray.train\n",
    "\n",
    "from model.GPT import GPT\n",
    "from utility import save_checkpoint, resume_checkpoint\n",
    "from text_generator import TextGenerator\n",
    "\n",
    "\n",
    "def train_loop_per_worker(config):\n",
    "    vocab_size = config[\"vocab_size\"]\n",
    "    dimension_embedding = config[\"dimension_embedding\"]\n",
    "    block_size = config[\"block_size\"]\n",
    "    num_layers = config[\"num_layers\"]\n",
    "    num_headers = config[\"num_headers\"]\n",
    "    drop_rate = config[\"drop_rate\"]\n",
    "    qkv_bias = config[\"qkv_bias\"]\n",
    "    check_frequency = config[\"check_frequency\"]\n",
    "    batch_size_per_worker = config[\"batch_size_per_worker\"]\n",
    "    num_epoch_per_worker = config[\"num_epoch_per_worker\"]\n",
    "    resume_training = config[\"resume_training\"]\n",
    "    best_checkpoint_dir = config[\"best_checkpoint_dir\"]\n",
    "    start_context = config[\"start_context\"]\n",
    "\n",
    "    # GPT model\n",
    "    model = GPT(\n",
    "        vocab_size,\n",
    "        dimension_embedding,\n",
    "        block_size,\n",
    "        num_layers,\n",
    "        num_headers,\n",
    "        drop_rate,\n",
    "        qkv_bias,\n",
    "    )\n",
    "    model = ray.train.torch.prepare_model(model)\n",
    "\n",
    "    # optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "    # ====== Resume training state from the checkpoint. ======\n",
    "    epoch_start = 0\n",
    "    best_perplexity = 1000000.0\n",
    "    best_epoch = 0\n",
    "\n",
    "    if resume_training:\n",
    "        if os.path.exists(best_checkpoint_dir):\n",
    "            checkpoint = ray.train.Checkpoint.from_directory(best_checkpoint_dir)\n",
    "        else:\n",
    "            checkpoint = None\n",
    "        if checkpoint:\n",
    "            best_epoch, best_perplexity = resume_checkpoint(model, optimizer, checkpoint)\n",
    "            epoch_start = best_epoch\n",
    "            print(\n",
    "                f\"Resumed training from best_epoch {best_epoch},best_perplexity {best_perplexity}\"\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Checkpoint not found, starting from epoch 0\")\n",
    "\n",
    "    # loss function\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    rank = ray.train.get_context().get_world_rank()\n",
    "    device = torch.device(f\"cuda:{rank}\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # metrics\n",
    "    metric = Perplexity().to(device)\n",
    "\n",
    "    # data\n",
    "    train_data_shard = ray.train.get_dataset_shard(\"train\")\n",
    "    validate_data_shard = ray.train.get_dataset_shard(\"validate\")\n",
    "\n",
    "    report_metrics = {\n",
    "        \"epoch\": 0,\n",
    "        \"train_loss\": 0.0,\n",
    "        \"validate_loss\": 0.0,\n",
    "        \"perplexity\": 0.0,\n",
    "        \"best_epoch\": best_epoch,\n",
    "        \"best_perplexity\": best_perplexity,\n",
    "    }\n",
    " \n",
    " \n",
    "    text_generator = TextGenerator(model,device=device)\n",
    "    tokenizer = TikTokenizer()\n",
    "    for epoch in range(epoch_start + 1, num_epoch_per_worker + 1):\n",
    "        \n",
    "        print(f\"epoch:{epoch}\")\n",
    "        \n",
    "        model.train()\n",
    "\n",
    "        report_metrics[\"epoch\"] = epoch\n",
    "\n",
    "        train_loss = 0\n",
    "        batch_count = 0\n",
    "        for batch in train_data_shard.iter_torch_batches(\n",
    "            batch_size=batch_size_per_worker,\n",
    "            drop_last=True,\n",
    "            local_shuffle_buffer_size=1000,\n",
    "        ):\n",
    "            \n",
    "            batch_count += 1\n",
    "            input_ids = batch[\"input_ids\"]\n",
    "            logits = model(input_ids)\n",
    "            \n",
    "            target_ids = batch[\"target_ids\"]\n",
    "            loss = loss_function(logits.flatten(0, 1), target_ids.flatten())\n",
    "            train_loss += loss.item()  # only for reporting\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss = train_loss / batch_count\n",
    "\n",
    "        report_metrics[\"train_loss\"] = train_loss\n",
    "\n",
    "        validate_loss = 0\n",
    "        perplexity = 0\n",
    "\n",
    "        if epoch % check_frequency == 0:\n",
    "\n",
    "            model.eval()\n",
    " \n",
    "\n",
    "            with torch.no_grad():\n",
    "                batch_count = 0\n",
    "                for batch in validate_data_shard.iter_torch_batches(\n",
    "                    batch_size=1,\n",
    "                    drop_last=False,\n",
    "                ):\n",
    "                    batch_count += 1\n",
    "                    input_ids = batch[\"input_ids\"]\n",
    "                    logits = model(input_ids)\n",
    "                    target_ids = batch[\"target_ids\"]\n",
    "                    loss = loss_function(logits.flatten(0, 1), target_ids.flatten())\n",
    "                    validate_loss += loss.item()  # only for reporting\n",
    "                    metric.update(logits, target_ids)\n",
    "\n",
    "            validate_loss = validate_loss / batch_count\n",
    "            perplexity = metric.compute().item()\n",
    "            metric.reset()\n",
    "\n",
    "            report_metrics[\"validate_loss\"] = validate_loss\n",
    "            report_metrics[\"perplexity\"] = perplexity\n",
    "\n",
    "\n",
    "            # In standard DDP training, where the model is the same across all ranks,\n",
    "            # only the global rank 0 worker needs to save and report the checkpoint\n",
    "            if ray.train.get_context().get_world_rank() == 0:\n",
    "                if perplexity < best_perplexity:\n",
    "                    best_perplexity = perplexity\n",
    "                    best_epoch = epoch\n",
    "                    \n",
    "                    report_metrics[\"best_epoch\"] = best_epoch\n",
    "                    report_metrics[\"best_perplexity\"] = best_perplexity\n",
    "\n",
    "\n",
    "                    # create the best_checkpoint_dir if it does not exist\n",
    "                    # if not os.path.exists(best_checkpoint_dir):\n",
    "                    #     os.makedirs(best_checkpoint_dir)\n",
    "\n",
    "                    # save_checkpoint(\n",
    "                    #     model,\n",
    "                    #     optimizer,\n",
    "                    #     epoch,\n",
    "                    #     perplexity,\n",
    "                    #     best_checkpoint_dir,\n",
    "                    # )\n",
    "\n",
    "                ray.train.report(metrics=report_metrics)\n",
    "                \n",
    "        decoded = text_generator(tokenizer.encode(start_context), max_new_tokens=50, context_size=block_size)\n",
    "        print(f\"\\n epoch{epoch}:{decoded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-06 07:36:55,013\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-08-06 07:36:55 (running for 00:00:00.14)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/128 CPUs, 0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:37:00 (running for 00:00:05.22)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:37:05 (running for 00:00:10.31)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:37:10 (running for 00:00:15.36)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:37:15 (running for 00:00:20.42)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:37:20 (running for 00:00:25.49)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(TrainTrainable pid=107333) 2024-08-06 07:37:01.681466: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "(TrainTrainable pid=107333) 2024-08-06 07:37:01.700048: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "(TrainTrainable pid=107333) 2024-08-06 07:37:01.720278: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "(TrainTrainable pid=107333) 2024-08-06 07:37:01.726258: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "(TrainTrainable pid=107333) 2024-08-06 07:37:01.742033: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "(TrainTrainable pid=107333) To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "(TrainTrainable pid=107333) 2024-08-06 07:37:02.915662: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "(RayTrainWorker pid=107441) Setting up process group for: env:// [rank=0, world_size=4]\n",
      "(RayTrainWorker pid=107443) [W806 07:37:10.975838671 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())\n",
      "(RayTrainWorker pid=107442) [W806 07:37:10.038721357 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())\n",
      "(RayTrainWorker pid=107444) [W806 07:37:11.795530965 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())\n",
      "(RayTrainWorker pid=107441) [W806 07:37:11.994463114 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())\n",
      "(TorchTrainer pid=107333) Started distributed worker processes: \n",
      "(TorchTrainer pid=107333) - (node_id=1bcd7b05ab0b5ec76478c51964fc8730cbbd5fd4d5e3e8f22c318454, ip=172.17.0.2, pid=107441) world_rank=0, local_rank=0, node_rank=0\n",
      "(TorchTrainer pid=107333) - (node_id=1bcd7b05ab0b5ec76478c51964fc8730cbbd5fd4d5e3e8f22c318454, ip=172.17.0.2, pid=107442) world_rank=1, local_rank=1, node_rank=0\n",
      "(TorchTrainer pid=107333) - (node_id=1bcd7b05ab0b5ec76478c51964fc8730cbbd5fd4d5e3e8f22c318454, ip=172.17.0.2, pid=107443) world_rank=2, local_rank=2, node_rank=0\n",
      "(TorchTrainer pid=107333) - (node_id=1bcd7b05ab0b5ec76478c51964fc8730cbbd5fd4d5e3e8f22c318454, ip=172.17.0.2, pid=107444) world_rank=3, local_rank=3, node_rank=0\n",
      "(RayTrainWorker pid=107443) 2024-08-06 07:37:12.391499: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "(RayTrainWorker pid=107444) 2024-08-06 07:37:12.391496: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "(RayTrainWorker pid=107441) 2024-08-06 07:37:12.316390: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "(RayTrainWorker pid=107441) 2024-08-06 07:37:12.334531: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "(RayTrainWorker pid=107441) 2024-08-06 07:37:12.354783: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "(RayTrainWorker pid=107441) 2024-08-06 07:37:12.360724: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "(RayTrainWorker pid=107441) 2024-08-06 07:37:12.376583: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "(RayTrainWorker pid=107441) To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "(RayTrainWorker pid=107442) 2024-08-06 07:37:12.382746: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "(RayTrainWorker pid=107442) 2024-08-06 07:37:12.400164: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "(RayTrainWorker pid=107443) 2024-08-06 07:37:12.409372: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "(RayTrainWorker pid=107444) 2024-08-06 07:37:12.409418: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "(RayTrainWorker pid=107442) 2024-08-06 07:37:12.420244: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "(RayTrainWorker pid=107442) 2024-08-06 07:37:12.426424: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "(RayTrainWorker pid=107443) 2024-08-06 07:37:12.429331: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "(RayTrainWorker pid=107443) 2024-08-06 07:37:12.435825: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "(RayTrainWorker pid=107444) 2024-08-06 07:37:12.429559: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "(RayTrainWorker pid=107444) 2024-08-06 07:37:12.435985: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "(RayTrainWorker pid=107442) 2024-08-06 07:37:12.441691: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "(RayTrainWorker pid=107442) To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "(RayTrainWorker pid=107443) 2024-08-06 07:37:12.451246: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "(RayTrainWorker pid=107443) To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "(RayTrainWorker pid=107444) 2024-08-06 07:37:12.451234: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "(RayTrainWorker pid=107444) To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "(RayTrainWorker pid=107443) 2024-08-06 07:37:13.555795: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "(RayTrainWorker pid=107444) 2024-08-06 07:37:13.514691: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "(RayTrainWorker pid=107441) 2024-08-06 07:37:13.476051: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "(RayTrainWorker pid=107442) 2024-08-06 07:37:13.564288: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=107441) number of parameters: 123.63M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=107441) Moving model to device: cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=107443) number of parameters: 123.63M\n",
      "(RayTrainWorker pid=107444) number of parameters: 123.63M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=107441) Wrapping provided model in DistributedDataParallel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=107442) number of parameters: 123.63M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=107443) [rank2]:[W806 07:37:21.467992741 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())\n",
      "(RayTrainWorker pid=107444) [rank3]:[W806 07:37:21.468142877 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())\n",
      "(RayTrainWorker pid=107441) [rank0]:[W806 07:37:21.481734396 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())\n",
      "(RayTrainWorker pid=107442) [rank1]:[W806 07:37:21.481847674 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=107443) epoch:1\n",
      "(RayTrainWorker pid=107444) epoch:1\n",
      "(RayTrainWorker pid=107441) epoch:1\n",
      "(RayTrainWorker pid=107442) epoch:1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3546794d84174e88b53259aee387d06d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=107838) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(SplitCoordinator pid=107838) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-06_07-36-40_105549_94856/logs/ray-data\n",
      "(SplitCoordinator pid=107838) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(4, equal=True)]\n",
      "(SplitCoordinator pid=107840) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-06_07-36-40_105549_94856/logs/ray-data\n",
      "(SplitCoordinator pid=107840) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(4, equal=True)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-08-06 07:37:25 (running for 00:00:30.55)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:37:30 (running for 00:00:35.59)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcb25b9e715b4b2cbf413fb55ba4ad01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=107840) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443)  epoch1:Every effort moves you\n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) epoch:2\n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441)  epoch1:Every effort moves you\n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) \n",
      "(RayTrainWorker pid=107441) epoch:2\n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442)  epoch1:Every effort moves you\n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) epoch:2\n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444)  epoch1:Every effort moves you\n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) epoch:2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3972747fe2f24a58a83f08c9a89bc425",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=107838) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(SplitCoordinator pid=107838) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-06_07-36-40_105549_94856/logs/ray-data\n",
      "(SplitCoordinator pid=107838) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(4, equal=True)]\n",
      "(SplitCoordinator pid=107840) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-06_07-36-40_105549_94856/logs/ray-data\n",
      "(SplitCoordinator pid=107840) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(4, equal=True)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-08-06 07:37:35 (running for 00:00:40.64)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5a8ae6d8ad843cb98b575380cd6c292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=107840) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443)  epoch2:Every effort moves you\n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) \n",
      "(RayTrainWorker pid=107443) epoch:3\n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444)  epoch2:Every effort moves you\n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) \n",
      "(RayTrainWorker pid=107444) epoch:3\n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442)  epoch2:Every effort moves you\n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) \n",
      "(RayTrainWorker pid=107442) epoch:3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-08-06 07:37:40 (running for 00:00:45.68)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:37:45 (running for 00:00:50.73)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:37:50 (running for 00:00:55.78)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:37:55 (running for 00:01:00.83)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:38:00 (running for 00:01:05.87)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:38:05 (running for 00:01:10.92)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:38:11 (running for 00:01:15.97)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:38:16 (running for 00:01:21.02)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:38:21 (running for 00:01:26.06)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:38:26 (running for 00:01:31.11)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:38:31 (running for 00:01:36.15)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:38:36 (running for 00:01:41.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:38:41 (running for 00:01:46.24)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:38:46 (running for 00:01:51.29)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:38:51 (running for 00:01:56.33)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:38:56 (running for 00:02:01.38)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:39:01 (running for 00:02:06.42)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:39:06 (running for 00:02:11.47)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:39:11 (running for 00:02:16.52)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:39:16 (running for 00:02:21.57)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:39:21 (running for 00:02:26.61)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:39:26 (running for 00:02:31.66)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:39:31 (running for 00:02:36.70)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:39:36 (running for 00:02:41.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:39:41 (running for 00:02:46.79)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:39:46 (running for 00:02:51.84)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:39:51 (running for 00:02:56.88)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:39:56 (running for 00:03:01.93)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:40:02 (running for 00:03:06.98)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:40:07 (running for 00:03:12.03)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:40:12 (running for 00:03:17.08)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:40:17 (running for 00:03:22.13)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:40:22 (running for 00:03:27.17)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:40:27 (running for 00:03:32.22)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:40:32 (running for 00:03:37.27)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:40:37 (running for 00:03:42.32)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:40:42 (running for 00:03:47.36)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:40:47 (running for 00:03:52.41)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:40:52 (running for 00:03:57.45)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:40:57 (running for 00:04:02.50)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:41:02 (running for 00:04:07.55)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:41:07 (running for 00:04:12.60)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:41:12 (running for 00:04:17.64)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:41:17 (running for 00:04:22.69)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:41:22 (running for 00:04:27.73)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:41:27 (running for 00:04:32.78)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:41:32 (running for 00:04:37.82)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:41:37 (running for 00:04:42.87)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:41:42 (running for 00:04:47.91)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:41:48 (running for 00:04:52.97)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:41:53 (running for 00:04:58.01)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:41:58 (running for 00:05:03.06)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:42:03 (running for 00:05:08.10)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:42:08 (running for 00:05:13.15)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:42:13 (running for 00:05:18.19)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:42:18 (running for 00:05:23.24)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:42:23 (running for 00:05:28.28)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:42:28 (running for 00:05:33.33)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:42:33 (running for 00:05:38.38)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:42:38 (running for 00:05:43.43)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:42:43 (running for 00:05:48.47)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:42:48 (running for 00:05:53.52)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:42:53 (running for 00:05:58.57)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:42:58 (running for 00:06:03.62)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:43:03 (running for 00:06:08.66)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:43:08 (running for 00:06:13.71)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:43:13 (running for 00:06:18.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:43:18 (running for 00:06:23.81)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:43:23 (running for 00:06:28.85)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:43:28 (running for 00:06:33.90)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:43:33 (running for 00:06:38.94)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:43:39 (running for 00:06:43.99)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:43:44 (running for 00:06:49.03)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-06 07:43:49 (running for 00:06:54.08)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 5.0/128 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-06_07-36-40_105549_94856/artifacts/2024-08-06_07-36-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(SplitCoordinator pid=107838) StreamSplitDataIterator(epoch=1, split=3) blocked waiting on other clients for more than 30s. All clients must read from the DataIterator splits at the same time. This warning will not be printed again for this epoch.\n",
      "(SplitCoordinator pid=107838) StreamSplitDataIterator(epoch=1, split=1) blocked waiting on other clients for more than 30s. All clients must read from the DataIterator splits at the same time. This warning will not be printed again for this epoch.\n",
      "(SplitCoordinator pid=107838) StreamSplitDataIterator(epoch=1, split=2) blocked waiting on other clients for more than 30s. All clients must read from the DataIterator splits at the same time. This warning will not be printed again for this epoch.\n"
     ]
    }
   ],
   "source": [
    "from ray.train.torch import TorchTrainer\n",
    "from ray.train import Result\n",
    "from ray import train\n",
    "\n",
    "train_loop_config = {\n",
    "    \"vocab_size\": cfg[\"124M\"][\"vocab_size\"],\n",
    "    \"dimension_embedding\": cfg[\"124M\"][\"dimension_embedding\"],\n",
    "    \"block_size\": cfg[\"124M\"][\"block_size\"],\n",
    "    \"num_layers\": cfg[\"124M\"][\"num_layers\"],\n",
    "    \"num_headers\": cfg[\"124M\"][\"num_headers\"],\n",
    "    \"drop_rate\": cfg[\"124M\"][\"drop_rate\"],\n",
    "    \"qkv_bias\": cfg[\"124M\"][\"qkv_bias\"],\n",
    "    \"check_frequency\": cfg[\"ray_train\"][\"check_frequency\"],\n",
    "    \"batch_size_per_worker\": cfg[\"ray_train\"][\"batch_size_per_worker\"],\n",
    "    \"num_epoch_per_worker\": cfg[\"ray_train\"][\"num_epoch_per_worker\"],\n",
    "    \"resume_training\":cfg[\"ray_train\"][\"resume_training\"],\n",
    "    \"best_checkpoint_dir\":cfg[\"ray_train\"][\"best_checkpoint_dir\"],\n",
    "    \"start_context\":cfg[\"ray_train\"][\"start_context\"],\n",
    "}\n",
    "\n",
    "\n",
    "trainer = TorchTrainer(\n",
    "    train_loop_per_worker=train_loop_per_worker,\n",
    "    train_loop_config=train_loop_config,\n",
    "    datasets={\n",
    "        \"train\": train_chunked_tokens,\n",
    "        \"validate\": validate_chunked_tokens,\n",
    "    },\n",
    "    scaling_config=ray.train.ScalingConfig(\n",
    "        num_workers=cfg[\"ray_train\"][\"num_workers\"],\n",
    "        use_gpu=cfg[\"ray_train\"][\"use_gpu\"],\n",
    "        resources_per_worker={\n",
    "            \"CPU\": cfg[\"ray_train\"][\"num_cpus_per_worker\"],\n",
    "            \"GPU\": cfg[\"ray_train\"][\"num_gpus_per_worker\"],\n",
    "        },\n",
    "    ),\n",
    "    run_config=train.RunConfig(\n",
    "        storage_path=cfg[\"ray_train\"][\"storage_path\"],\n",
    "        name=cfg[\"ray_train\"][\"name\"],\n",
    "    ),\n",
    "    \n",
    ")\n",
    "result: Result = trainer.fit()\n",
    "print(result.metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
