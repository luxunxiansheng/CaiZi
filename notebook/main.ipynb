{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "project_root = os.path.dirname(os.getcwd())\n",
    "sys.path.append(f\"{project_root}/src\")\n",
    "sys.path.append(f\"{project_root}/third_party\")\n",
    "\n",
    "from config import gpt2_cfg as cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 09:11:51,651\tINFO worker.py:1772 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "2024-08-02 09:11:51,656\tINFO packaging.py:530 -- Creating a file package for local directory '/workspaces/CaiZi'.\n",
      "2024-08-02 09:11:51,662\tINFO packaging.py:358 -- Pushing file package 'gcs://_ray_pkg_6c71d926d037020d.zip' (0.32MiB) to Ray cluster...\n",
      "2024-08-02 09:11:51,664\tINFO packaging.py:371 -- Successfully pushed file package 'gcs://_ray_pkg_6c71d926d037020d.zip'.\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "if ray.is_initialized():\n",
    "    ray.shutdown()\n",
    "\n",
    "\n",
    "ray.init(\n",
    "        runtime_env={\n",
    "            \"env_vars\": {          \n",
    "                \"PYTHONPATH\": \"$PYTHONPATH:\" + cfg.project_root + \"/src\",\n",
    "            },\n",
    "            \"working_dir\": cfg.project_root,\n",
    "            \"excludes\": [\n",
    "                \"/bazel-*\",\n",
    "                \".git\",\n",
    "                \"*.pyc\",\n",
    "                \"/__pycache__\",\n",
    "                \"/outputs\",\n",
    "                \"/model\",\n",
    "            ],\n",
    "        },\n",
    "      \n",
    "    )\n",
    "# convience for debugging\n",
    "ray.data.DataContext.get_current().execution_options.verbose_progress = True\n",
    "ray.data.DataContext.log_internal_stack_trace_to_stdout = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "data_sources = [ Path(item[\"path\"]) for item in cfg[\"dataset\"]]\n",
    "text_document_paths = ray.data.from_items(data_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from document_processor import TextDocumentProcessor\n",
    "train_text_document_processor = TextDocumentProcessor(section=\"train\")\n",
    "train_texts=text_document_paths.map(train_text_document_processor)\n",
    "\n",
    "validate_text_document_processor = TextDocumentProcessor(section=\"validate\")\n",
    "validate_texts=text_document_paths.map(validate_text_document_processor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from token_processor import TikTokenizer\n",
    "tokenizer = TikTokenizer()\n",
    "train_tokens = train_texts.map(tokenizer)\n",
    "validate_tokens = validate_texts.map(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chunk_processor import ChunkProcessor\n",
    "\n",
    "chunk_processor = ChunkProcessor(max_length=cfg[\"124M\"][\"block_size\"],stride=cfg[\"124M\"][\"stride\"])\n",
    "train_chunked_tokens = train_tokens.flat_map(chunk_processor)\n",
    "validate_chunked_tokens = validate_tokens.flat_map(chunk_processor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "\n",
    "import ray.train\n",
    "import torch\n",
    "from torchmetrics.text import Perplexity\n",
    "\n",
    "import ray\n",
    "from ray.train import Checkpoint\n",
    "\n",
    "from model.GPT import GPT\n",
    "from utility import save_checkpoint, resume_checkpoint\n",
    "\n",
    "train_loop_config = {\n",
    "    \"vocab_size\": cfg[\"124M\"][\"vocab_size\"],\n",
    "    \"dimension_embedding\": cfg[\"124M\"][\"dimension_embedding\"],\n",
    "    \"block_size\": cfg[\"124M\"][\"block_size\"],\n",
    "    \"num_layers\": cfg[\"124M\"][\"num_layers\"],\n",
    "    \"num_headers\": cfg[\"124M\"][\"num_headers\"],\n",
    "    \"drop_rate\": cfg[\"124M\"][\"drop_rate\"],\n",
    "    \"qkv_bias\": cfg[\"124M\"][\"qkv_bias\"],\n",
    "    \"check_frequency\": cfg[\"ray_train\"][\"check_frequency\"],\n",
    "    \"batch_size_per_worker\": cfg[\"ray_train\"][\"batch_size_per_worker\"],\n",
    "    \"num_epoch_per_worker\": cfg[\"ray_train\"][\"num_epoch_per_worker\"],\n",
    "}\n",
    "\n",
    "\n",
    "def train_loop_per_worker(config):\n",
    "    vocab_size = config[\"vocab_size\"]\n",
    "    dimension_embedding = config[\"dimension_embedding\"]\n",
    "    block_size = config[\"block_size\"]\n",
    "    num_layers = config[\"num_layers\"]\n",
    "    num_headers = config[\"num_headers\"]\n",
    "    drop_rate = config[\"drop_rate\"]\n",
    "    qkv_bias = config[\"qkv_bias\"]\n",
    "    check_frequency = config[\"check_frequency\"]\n",
    "    batch_size_per_worker = config[\"batch_size_per_worker\"]\n",
    "    num_epoch_per_worker = config[\"num_epoch_per_worker\"]\n",
    "\n",
    "    # GPT model\n",
    "    model = GPT(\n",
    "        vocab_size,\n",
    "        dimension_embedding,\n",
    "        block_size,\n",
    "        num_layers,\n",
    "        num_headers,\n",
    "        drop_rate,\n",
    "        qkv_bias,\n",
    "    )\n",
    "    model = ray.train.torch.prepare_model(model)\n",
    "\n",
    "    # optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "    # ====== Resume training state from the checkpoint. ======\n",
    "    epoch_start = 0\n",
    "\n",
    "    checkpoint = ray.train.get_checkpoint()\n",
    "    if checkpoint:\n",
    "        epoch_start = resume_checkpoint(model, optimizer, checkpoint)\n",
    "\n",
    "    # loss function\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    rank = ray.train.get_context().get_world_rank()\n",
    "    device = torch.device(f\"cuda:{rank}\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # metrics\n",
    "    metric = Perplexity().to(device)\n",
    "\n",
    "    # data\n",
    "    train_data_shard = ray.train.get_dataset_shard(\"train\")\n",
    "    validate_data_shard = ray.train.get_dataset_shard(\"validate\")\n",
    "\n",
    "    report_metrics = {\"epoch\": 0, \"train_loss\": 0.0, \"validate_loss\": 0.0, \"perplexity\": 0.0}\n",
    "    for epoch in range(epoch_start, num_epoch_per_worker):\n",
    "        model.train()\n",
    "        \n",
    "        report_metrics[\"epoch\"] = epoch\n",
    "        \n",
    "        train_loss = 0\n",
    "        batch_count = 0\n",
    "        for batch in train_data_shard.iter_torch_batches(\n",
    "            batch_size=batch_size_per_worker,\n",
    "            drop_last=True,\n",
    "            local_shuffle_buffer_size=1000,\n",
    "        ):\n",
    "            batch_count += 1\n",
    "            input_ids = batch[\"input_ids\"]\n",
    "            logits = model(input_ids)\n",
    "            target_ids = batch[\"target_ids\"]\n",
    "            loss = loss_function(logits.flatten(0, 1), target_ids.flatten())\n",
    "            train_loss += loss.item()  # only for reporting\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss = train_loss / batch_count\n",
    "        \n",
    "        report_metrics[\"train_loss\"] = train_loss\n",
    "        \n",
    "        validate_loss = 0\n",
    "        perplexity = 0\n",
    "        checkpoint = None\n",
    "\n",
    "        if epoch % check_frequency == 0:\n",
    "\n",
    "            model.eval()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                batch_count = 0\n",
    "                for batch in validate_data_shard.iter_torch_batches(\n",
    "                    batch_size=1,\n",
    "                    drop_last=False,\n",
    "                ):\n",
    "                    batch_count += 1\n",
    "                    input_ids = batch[\"input_ids\"]\n",
    "                    logits = model(input_ids)\n",
    "                    target_ids = batch[\"target_ids\"]\n",
    "                    loss = loss_function(logits.flatten(0, 1), target_ids.flatten())\n",
    "                    validate_loss += loss.item()  # only for reporting\n",
    "                    metric.update(logits, target_ids)\n",
    "\n",
    "            validate_loss = validate_loss / batch_count\n",
    "            perplexity = metric.compute().item()\n",
    "            metric.reset()\n",
    "            \n",
    "            report_metrics[\"validate_loss\"] = validate_loss\n",
    "            report_metrics[\"perplexity\"] = perplexity\n",
    "\n",
    "            with tempfile.TemporaryDirectory() as temp_checkpoint_dir:\n",
    "                # In standard DDP training, where the model is the same across all ranks,\n",
    "                # only the global rank 0 worker needs to save and report the checkpoint\n",
    "                if ray.train.get_context().get_world_rank() == 0:\n",
    "                    # === Make sure to save all state needed for resuming training ===\n",
    "                    save_checkpoint(model, optimizer, epoch, temp_checkpoint_dir)\n",
    "                    checkpoint =  Checkpoint.from_directory(temp_checkpoint_dir)\n",
    "\n",
    "                ray.train.report(\n",
    "                    metrics=report_metrics,\n",
    "                    checkpoint=checkpoint,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 09:11:55,181\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-08-02 09:11:55 (running for 00:00:00.11)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-02_09-11-50_921992_224777/artifacts/2024-08-02_09-11-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-02 09:12:00 (running for 00:00:05.13)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-02_09-11-50_921992_224777/artifacts/2024-08-02_09-11-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TorchTrainer pid=227183)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(TorchTrainer pid=227183)\u001b[0m - (node_id=2a13ba843ae388e40be93d48336a6ae800c6b9ccb4e90b961169ae36, ip=172.17.0.2, pid=227540) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(RayTrainWorker pid=227540)\u001b[0m Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[36m(RayTrainWorker pid=227540)\u001b[0m [W802 09:11:59.178182595 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())\n",
      "\u001b[36m(RayTrainWorker pid=227540)\u001b[0m Moving model to device: cuda:0\n",
      "\u001b[36m(SplitCoordinator pid=227613)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-02_09-11-50_921992_224777/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=227613)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n",
      "\u001b[36m(RayTrainWorker pid=227540)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/workspaces/CaiZi/outputs/gpt2/124M/TorchTrainer_43631_00000_0_2024-08-02_09-11-55/checkpoint_000000)\n",
      "\u001b[36m(SplitCoordinator pid=227613)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-02_09-11-50_921992_224777/logs/ray-data\u001b[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(SplitCoordinator pid=227613)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=227540)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/workspaces/CaiZi/outputs/gpt2/124M/TorchTrainer_43631_00000_0_2024-08-02_09-11-55/checkpoint_000001)\n",
      "\u001b[36m(SplitCoordinator pid=227614)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-02_09-11-50_921992_224777/logs/ray-data\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(SplitCoordinator pid=227614)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=227540)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/workspaces/CaiZi/outputs/gpt2/124M/TorchTrainer_43631_00000_0_2024-08-02_09-11-55/checkpoint_000002)\n",
      "\u001b[36m(SplitCoordinator pid=227614)\u001b[0m Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-02_09-11-50_921992_224777/logs/ray-data\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(SplitCoordinator pid=227614)\u001b[0m Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=227540)\u001b[0m [rank0]:[W802 09:12:19.696774004 ProcessGroupNCCL.cpp:1168] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42b2f216db6642e7a5badbd267eb0450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227613) - Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor) 1: 0 bundle [00:00, ? bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a85da6fbb644468a6af2c449fc2705d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227613) - split(1, equal=True) 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42d824e6c8c74c57911c79995e0224ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227613) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bc2da681a914fcca159dbc1316c6d5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227614) - Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor) 1: 0 bundle [00:00, ? bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3f4c00cfa9348ea8d5e59c4e70b85bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227614) - split(1, equal=True) 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb7f091ae8d64f2fa3d51dc25d881d0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227614) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-08-02 09:12:05 (running for 00:00:10.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-02_09-11-50_921992_224777/artifacts/2024-08-02_09-11-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f37c69409a0642198a365e63d04386be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227613) - Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor) 1: 0 bundle [00:00, ? bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "197018a346694ddb8b49719f33cea361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227613) - split(1, equal=True) 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9e1ebe5a62f465d9246095cb62db3bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227613) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bb51a724c5d48a991672e306f00746f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227613) - Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor) 1: 0 bundle [00:00, ? bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42c8ca3f9fed4c2ab2bc986735067195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227613) - split(1, equal=True) 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20bd55caa9f04782a9e4979fa27d0cdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227613) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8fef9e4a9614f828e234942c9169586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227613) - Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor) 1: 0 bundle [00:00, ? bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76781ead42b44cceba3fd1db7d3bdf9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227613) - split(1, equal=True) 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbca24862aa94b4e8697896bf6d6ba8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227613) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2a1525df9584f83b075887d099367ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227613) - Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor) 1: 0 bundle [00:00, ? bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cc209e5e1fa4d3daaafcea51f2d6194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227613) - split(1, equal=True) 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa0a96afb1c543939dbf50fd26326232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227613) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50a2b1a0c32a4d2aae3f33a3e2a2b100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227613) - Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor) 1: 0 bundle [00:00, ? bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "690b643b0d774c35991b43cb5d4ca0e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227613) - split(1, equal=True) 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d8d5a7315e945329928cea1e5d41290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227613) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a09f5f86adf45778ef5bb64fa5329fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227614) - Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor) 1: 0 bundle [00:00, ? bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52e0dba328574c6fb6acec911f30d099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227614) - split(1, equal=True) 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "196361762a584109a48067ac782cafd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227614) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-08-02 09:12:10 (running for 00:00:15.22)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-02_09-11-50_921992_224777/artifacts/2024-08-02_09-11-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09584d88501d4e87888922f29134b90b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227613) - Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor) 1: 0 bundle [00:00, ? bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12787208264a4495adc3f48a58fb18df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227613) - split(1, equal=True) 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "482c43aaa741471db9031a6e2a33b671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227613) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09cd9bb84b614253a48d83d74da01955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227613) - Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor) 1: 0 bundle [00:00, ? bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "600254f7234a4d35bfff8bf0303c4ebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227613) - split(1, equal=True) 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90570d70b3db4033aafe1052dd604340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227613) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9d606b484254fdeab6771f7999cc989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227613) - Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor) 1: 0 bundle [00:00, ? bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd02dfb3e2b043d4a6ca5f32d84c4402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227613) - split(1, equal=True) 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e378879d318b477e801cc76e95e188a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227613) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dae3b6cfd9b40c28d84fa7300508284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227613) - Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor) 1: 0 bundle [00:00, ? bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44d06c501f1248fbac7a8d67c9cd40cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227613) - split(1, equal=True) 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42d8eb0e1e8c487fae8062d97fd78a8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227613) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a30518987d34f859a9fabfd30e4d122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227613) - Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor) 1: 0 bundle [00:00, ? bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "930a90f513ef4cef89b5d33c2e423a83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227613) - split(1, equal=True) 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "350c7e9c9ffd45d5ad733499a8c46973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227613) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "544037c557a1444fb8896aec0eb05299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227614) - Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor) 1: 0 bundle [00:00, ? bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64595e1620e54427aedbbe488bf938e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227614) - split(1, equal=True) 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0e9be86c483417db19fc098ee81a2a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227614) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-08-02 09:12:15 (running for 00:00:20.24)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-02_09-11-50_921992_224777/artifacts/2024-08-02_09-11-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd85df6fd4744f009e15d8cb75929b45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227613) - Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor) 1: 0 bundle [00:00, ? bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b5782f6c5ef4037b0efa6c150f9c29f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227613) - split(1, equal=True) 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a1196db6b214be793eb1e41edc7095f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227613) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c9d2fa45bc24ea7957c52445e5e74ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227613) - Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor) 1: 0 bundle [00:00, ? bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42488f7ee9cc4b21909860f8c83fbb52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227613) - split(1, equal=True) 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "858f33cec6fc4b1e8cb9a98befcbdff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227613) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec180798056c455283acc7f7a8382d5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227613) - Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor) 1: 0 bundle [00:00, ? bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e40a1dda57a9417e971344a721bd153b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227613) - split(1, equal=True) 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "737db910470f4c7f93747281cfa5d266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227613) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "690955e90cec432e858faad6793f90ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227613) - Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor) 1: 0 bundle [00:00, ? bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0da22f7638c5439d945d3619daa2d38d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227613) - split(1, equal=True) 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "436b2f7d00f144e9a55b6aad71f4f2f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=227613) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 09:12:19,794\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/workspaces/CaiZi/outputs/gpt2/124M' in 0.0017s.\n",
      "2024-08-02 09:12:19,794\tINFO tune.py:1041 -- Total run time: 24.61 seconds (24.60 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-08-02 09:12:19 (running for 00:00:24.60)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-02_09-11-50_921992_224777/artifacts/2024-08-02_09-11-55/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 TERMINATED)\n",
      "\n",
      "\n",
      "{'epoch': 10, 'train_loss': 1.016655594110489, 'validate_loss': 6.5713417530059814, 'perplexity': 714.3267822265625, 'timestamp': 1722589934, 'checkpoint_dir_name': 'checkpoint_000002', 'should_checkpoint': True, 'done': True, 'training_iteration': 3, 'trial_id': '43631_00000', 'date': '2024-08-02_09-12-17', 'time_this_iter_s': 6.307123899459839, 'time_total_s': 19.69325876235962, 'pid': 227183, 'hostname': '569d72e6c54c', 'node_ip': '172.17.0.2', 'config': {'train_loop_config': {'vocab_size': 50257, 'dimension_embedding': 768, 'block_size': 256, 'num_layers': 12, 'num_headers': 12, 'drop_rate': 0.1, 'qkv_bias': False, 'check_frequency': 5, 'batch_size_per_worker': 4, 'num_epoch_per_worker': 15}}, 'time_since_restore': 19.69325876235962, 'iterations_since_restore': 3, 'experiment_tag': '0'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from ray.train.torch import TorchTrainer\n",
    "from ray.train import Result\n",
    "from ray import train\n",
    "\n",
    "trainer = TorchTrainer(\n",
    "    train_loop_per_worker=train_loop_per_worker,\n",
    "    train_loop_config=train_loop_config,\n",
    "    datasets={\n",
    "        \"train\": train_chunked_tokens,\n",
    "        \"validate\": validate_chunked_tokens,\n",
    "    },\n",
    "    scaling_config=ray.train.ScalingConfig(\n",
    "        num_workers=cfg[\"ray_train\"][\"num_workers\"],\n",
    "        use_gpu=cfg[\"ray_train\"][\"use_gpu\"],\n",
    "        resources_per_worker={\n",
    "            \"CPU\": cfg[\"ray_train\"][\"num_cpus_per_worker\"],\n",
    "            \"GPU\": cfg[\"ray_train\"][\"num_gpus_per_worker\"],\n",
    "        },\n",
    "    ),\n",
    "    run_config=train.RunConfig(\n",
    "            storage_path=cfg[\"ray_train\"][\"storage_path\"],\n",
    "            name = cfg[\"ray_train\"][\"name\"],\n",
    "            checkpoint_config=ray.train.CheckpointConfig(\n",
    "            num_to_keep=2,\n",
    "            # *Best* checkpoints are determined by these params:\n",
    "            checkpoint_score_attribute=\"perplexity\",\n",
    "            checkpoint_score_order=\"min\",\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "result: Result = trainer.fit()\n",
    "print(result.metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
