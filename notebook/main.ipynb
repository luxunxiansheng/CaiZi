{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "project_root = os.path.dirname(os.getcwd())\n",
    "sys.path.append(f\"{project_root}/src\")\n",
    "sys.path.append(f\"{project_root}/third_party\")\n",
    "\n",
    "os.environ[\"RAY_DEDUP_LOGS\"] = \"0\"\n",
    "os.environ[\"RAY_COLOR_PREFIX\"] = \"0\"\n",
    "\n",
    "from config import gpt2_cfg as cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 13:28:35,136\tINFO worker.py:1772 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "2024-08-02 13:28:35,142\tINFO packaging.py:530 -- Creating a file package for local directory '/workspaces/CaiZi'.\n",
      "2024-08-02 13:28:35,147\tINFO packaging.py:358 -- Pushing file package 'gcs://_ray_pkg_891678a0e78684b4.zip' (0.32MiB) to Ray cluster...\n",
      "2024-08-02 13:28:35,149\tINFO packaging.py:371 -- Successfully pushed file package 'gcs://_ray_pkg_891678a0e78684b4.zip'.\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "if ray.is_initialized():\n",
    "    ray.shutdown()\n",
    "\n",
    "ray.init(\n",
    "        runtime_env={\n",
    "            \"env_vars\": {          \n",
    "                \"PYTHONPATH\": \"$PYTHONPATH:\" + cfg.project_root + \"/src\",\n",
    "                \"RAY_DATA_VERBOSE_PROGRESS\": \"1\",\n",
    "            },\n",
    "            \"working_dir\": cfg.project_root,\n",
    "            \"excludes\": [\n",
    "                \"/bazel-*\",\n",
    "                \".git\",\n",
    "                \"*.pyc\",\n",
    "                \"/__pycache__\",\n",
    "                \"/outputs\",\n",
    "                \"/model\",\n",
    "            ],\n",
    "        },\n",
    "        ignore_reinit_error=True,\n",
    "    )\n",
    "\n",
    "# convience for debugging\n",
    "ray.data.DataContext.get_current().execution_options.verbose_progress = True\n",
    "ray.data.DataContext.log_internal_stack_trace_to_stdout = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "data_sources = [ Path(item[\"path\"]) for item in cfg[\"dataset\"]]\n",
    "text_document_paths = ray.data.from_items(data_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from document_processor import TextDocumentProcessor\n",
    "train_text_document_processor = TextDocumentProcessor(section=\"train\")\n",
    "train_texts=text_document_paths.map(train_text_document_processor)\n",
    "\n",
    "validate_text_document_processor = TextDocumentProcessor(section=\"validate\")\n",
    "validate_texts=text_document_paths.map(validate_text_document_processor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from token_processor import TikTokenizer\n",
    "tokenizer = TikTokenizer()\n",
    "train_tokens = train_texts.map(tokenizer)\n",
    "validate_tokens = validate_texts.map(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chunk_processor import ChunkProcessor\n",
    "\n",
    "chunk_processor = ChunkProcessor(max_length=cfg[\"124M\"][\"block_size\"],stride=cfg[\"124M\"][\"stride\"])\n",
    "train_chunked_tokens = train_tokens.flat_map(chunk_processor)\n",
    "validate_chunked_tokens = validate_tokens.flat_map(chunk_processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchmetrics.text import Perplexity\n",
    "\n",
    "import ray\n",
    "import ray.train\n",
    "from ray.train import Checkpoint\n",
    "\n",
    "from model.GPT import GPT\n",
    "from utility import save_checkpoint, resume_checkpoint\n",
    "\n",
    "\n",
    "def train_loop_per_worker(config):\n",
    "    vocab_size = config[\"vocab_size\"]\n",
    "    dimension_embedding = config[\"dimension_embedding\"]\n",
    "    block_size = config[\"block_size\"]\n",
    "    num_layers = config[\"num_layers\"]\n",
    "    num_headers = config[\"num_headers\"]\n",
    "    drop_rate = config[\"drop_rate\"]\n",
    "    qkv_bias = config[\"qkv_bias\"]\n",
    "    check_frequency = config[\"check_frequency\"]\n",
    "    batch_size_per_worker = config[\"batch_size_per_worker\"]\n",
    "    num_epoch_per_worker = config[\"num_epoch_per_worker\"]\n",
    "    resume_training = config[\"resume_training\"]\n",
    "    best_checkpoint_dir = config[\"best_checkpoint_dir\"]\n",
    "\n",
    "    # GPT model\n",
    "    model = GPT(\n",
    "        vocab_size,\n",
    "        dimension_embedding,\n",
    "        block_size,\n",
    "        num_layers,\n",
    "        num_headers,\n",
    "        drop_rate,\n",
    "        qkv_bias,\n",
    "    )\n",
    "    model = ray.train.torch.prepare_model(model)\n",
    "\n",
    "    # optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "    # ====== Resume training state from the checkpoint. ======\n",
    "    epoch_start = 0\n",
    "    best_perplexity = float(\"inf\")\n",
    "    best_epoch = 0\n",
    "\n",
    "    if resume_training:\n",
    "        if os.path.exists(best_checkpoint_dir):\n",
    "            checkpoint = ray.train.Checkpoint.from_directory(best_checkpoint_dir)\n",
    "        else:\n",
    "            checkpoint = None\n",
    "        if checkpoint:\n",
    "            best_epoch, best_perplexity = resume_checkpoint(model, optimizer, checkpoint)\n",
    "            print(\n",
    "                f\"Resumed training from best_epoch {best_epoch},best_perplexity {best_perplexity}\"\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Checkpoint not found, starting from epoch 0\")\n",
    "\n",
    "    # loss function\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    rank = ray.train.get_context().get_world_rank()\n",
    "    device = torch.device(f\"cuda:{rank}\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # metrics\n",
    "    metric = Perplexity().to(device)\n",
    "\n",
    "    # data\n",
    "    train_data_shard = ray.train.get_dataset_shard(\"train\")\n",
    "    validate_data_shard = ray.train.get_dataset_shard(\"validate\")\n",
    "\n",
    "    report_metrics = {\n",
    "        \"epoch\": 0,\n",
    "        \"train_loss\": 0.0,\n",
    "        \"validate_loss\": 0.0,\n",
    "        \"perplexity\": 0.0,\n",
    "    }\n",
    "\n",
    "    for epoch in range(epoch_start + 1, num_epoch_per_worker + 1):\n",
    "        model.train()\n",
    "\n",
    "        report_metrics[\"epoch\"] = epoch\n",
    "\n",
    "        train_loss = 0\n",
    "        batch_count = 0\n",
    "        for batch in train_data_shard.iter_torch_batches(\n",
    "            batch_size=batch_size_per_worker,\n",
    "            drop_last=True,\n",
    "            local_shuffle_buffer_size=1000,\n",
    "        ):\n",
    "            batch_count += 1\n",
    "            input_ids = batch[\"input_ids\"]\n",
    "            logits = model(input_ids)\n",
    "            target_ids = batch[\"target_ids\"]\n",
    "            loss = loss_function(logits.flatten(0, 1), target_ids.flatten())\n",
    "            train_loss += loss.item()  # only for reporting\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss = train_loss / batch_count\n",
    "\n",
    "        report_metrics[\"train_loss\"] = train_loss\n",
    "\n",
    "        validate_loss = 0\n",
    "        perplexity = 0\n",
    "\n",
    "        if epoch % check_frequency == 0:\n",
    "\n",
    "            model.eval()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                batch_count = 0\n",
    "                for batch in validate_data_shard.iter_torch_batches(\n",
    "                    batch_size=1,\n",
    "                    drop_last=False,\n",
    "                ):\n",
    "                    batch_count += 1\n",
    "                    input_ids = batch[\"input_ids\"]\n",
    "                    logits = model(input_ids)\n",
    "                    target_ids = batch[\"target_ids\"]\n",
    "                    loss = loss_function(logits.flatten(0, 1), target_ids.flatten())\n",
    "                    validate_loss += loss.item()  # only for reporting\n",
    "                    metric.update(logits, target_ids)\n",
    "\n",
    "            validate_loss = validate_loss / batch_count\n",
    "            perplexity = metric.compute().item()\n",
    "            metric.reset()\n",
    "\n",
    "            report_metrics[\"validate_loss\"] = validate_loss\n",
    "            report_metrics[\"perplexity\"] = perplexity\n",
    "            report_metrics[\"best_epoch\"] = best_epoch\n",
    "            report_metrics[\"best_perplexity\"] = best_perplexity\n",
    "\n",
    "            # In standard DDP training, where the model is the same across all ranks,\n",
    "            # only the global rank 0 worker needs to save and report the checkpoint\n",
    "            if ray.train.get_context().get_world_rank() == 0:\n",
    "                if perplexity < best_perplexity:\n",
    "                    best_perplexity = perplexity\n",
    "                    best_epoch = epoch\n",
    "\n",
    "                    # create the best_checkpoint_dir if it does not exist\n",
    "                    if not os.path.exists(best_checkpoint_dir):\n",
    "                        os.makedirs(best_checkpoint_dir)\n",
    "\n",
    "                    save_checkpoint(\n",
    "                        model,\n",
    "                        optimizer,\n",
    "                        epoch,\n",
    "                        perplexity,\n",
    "                        best_checkpoint_dir,\n",
    "                    )\n",
    "\n",
    "                ray.train.report(metrics=report_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 13:28:38,600\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-08-02 13:28:38 (running for 00:00:00.11)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-02_13-28-34_407310_432788/artifacts/2024-08-02_13-28-38/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-08-02 13:28:43 (running for 00:00:05.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-02_13-28-34_407310_432788/artifacts/2024-08-02_13-28-38/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(TorchTrainer pid=435232) Started distributed worker processes: \n",
      "(TorchTrainer pid=435232) - (node_id=05b22615e8a4cafa239a671ee5d7134909a17e17dbf9c30248c66a7a, ip=172.17.0.2, pid=435588) world_rank=0, local_rank=0, node_rank=0\n",
      "(RayTrainWorker pid=435588) Setting up process group for: env:// [rank=0, world_size=1]\n",
      "(RayTrainWorker pid=435588) [W802 13:28:42.553165598 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())\n",
      "(RayTrainWorker pid=435588) Moving model to device: cuda:0\n",
      "(RayTrainWorker pid=435588) /workspaces/CaiZi/src/utility.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "(RayTrainWorker pid=435588)   model_state_dict = torch.load(\n",
      "(RayTrainWorker pid=435588) /workspaces/CaiZi/src/utility.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "(RayTrainWorker pid=435588)   torch.load(os.path.join(checkpoint_dir, \"optimizer.pt\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=435588) Resumed training from best_epoch 9,best_perplexity 503.8351135253906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=435588) /workspaces/CaiZi/src/utility.py:59: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "(RayTrainWorker pid=435588)   extra_state = torch.load(os.path.join(checkpoint_dir, \"extra_state.pt\"))\n",
      "(SplitCoordinator pid=435664) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-02_13-28-34_407310_432788/logs/ray-data\n",
      "(SplitCoordinator pid=435664) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n",
      "(SplitCoordinator pid=435664) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-02_13-28-34_407310_432788/logs/ray-data\n",
      "(SplitCoordinator pid=435664) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n",
      "(SplitCoordinator pid=435664) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-02_13-28-34_407310_432788/logs/ray-data\n",
      "(SplitCoordinator pid=435664) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n",
      "(SplitCoordinator pid=435665) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-02_13-28-34_407310_432788/logs/ray-data\n",
      "(SplitCoordinator pid=435665) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n",
      "(SplitCoordinator pid=435664) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-02_13-28-34_407310_432788/logs/ray-data\n",
      "(SplitCoordinator pid=435664) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n",
      "(SplitCoordinator pid=435664) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-02_13-28-34_407310_432788/logs/ray-data\n",
      "(SplitCoordinator pid=435664) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n",
      "(SplitCoordinator pid=435664) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-02_13-28-34_407310_432788/logs/ray-data\n",
      "(SplitCoordinator pid=435664) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n",
      "(SplitCoordinator pid=435665) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-02_13-28-34_407310_432788/logs/ray-data\n",
      "(SplitCoordinator pid=435665) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n",
      "(SplitCoordinator pid=435664) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-02_13-28-34_407310_432788/logs/ray-data\n",
      "(SplitCoordinator pid=435664) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n",
      "(SplitCoordinator pid=435664) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-02_13-28-34_407310_432788/logs/ray-data\n",
      "(SplitCoordinator pid=435664) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n",
      "(SplitCoordinator pid=435664) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-02_13-28-34_407310_432788/logs/ray-data\n",
      "(SplitCoordinator pid=435664) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n",
      "(SplitCoordinator pid=435665) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-02_13-28-34_407310_432788/logs/ray-data\n",
      "(SplitCoordinator pid=435665) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n",
      "(SplitCoordinator pid=435664) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-02_13-28-34_407310_432788/logs/ray-data\n",
      "(SplitCoordinator pid=435664) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n",
      "(SplitCoordinator pid=435664) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-02_13-28-34_407310_432788/logs/ray-data\n",
      "(SplitCoordinator pid=435664) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n",
      "(SplitCoordinator pid=435664) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-02_13-28-34_407310_432788/logs/ray-data\n",
      "(SplitCoordinator pid=435664) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n",
      "(SplitCoordinator pid=435665) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-02_13-28-34_407310_432788/logs/ray-data\n",
      "(SplitCoordinator pid=435665) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n",
      "(SplitCoordinator pid=435664) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-02_13-28-34_407310_432788/logs/ray-data\n",
      "(SplitCoordinator pid=435664) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n",
      "(SplitCoordinator pid=435664) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-02_13-28-34_407310_432788/logs/ray-data\n",
      "(SplitCoordinator pid=435664) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n",
      "(SplitCoordinator pid=435664) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-02_13-28-34_407310_432788/logs/ray-data\n",
      "(SplitCoordinator pid=435664) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n",
      "(SplitCoordinator pid=435665) Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-02_13-28-34_407310_432788/logs/ray-data\n",
      "(SplitCoordinator pid=435665) Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor)] -> OutputSplitter[split(1, equal=True)]\n",
      "(RayTrainWorker pid=435588) [rank0]:[W802 13:28:50.995949009 ProcessGroupNCCL.cpp:1168] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4d199ab6cb142489bb6101dabcbee23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435664) - Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor) 1: 0 bundle [00:00, ? bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c62cdf963f8e48aab48e548044e79e0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435664) - split(1, equal=True) 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94859ee48dd442418efd8f2cb76bf218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435664) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56b238f7ece142c1a582843f4c42e6c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435664) - Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor) 1: 0 bundle [00:00, ? bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "221bb81612b64bf585730f5002e349c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435664) - split(1, equal=True) 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a15ff59486604c3ab8296f4b1ef9ddfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435664) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea56a38f500743df98e4154deb84fc6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435664) - Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor) 1: 0 bundle [00:00, ? bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bf49d354dec4699a8b45fc237bafc29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435664) - split(1, equal=True) 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afb5722b277b497fac8b7a94d303799b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435664) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6cc404b21884bdfa7da4cae52fb2e9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435665) - Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor) 1: 0 bundle [00:00, ? bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "456a17b7ff5e427e8776cead86d3e9f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435665) - split(1, equal=True) 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4ee7d208ce84bf1a355413cdabc2934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435665) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6226b0c7dc3433f8f8e62088b4bf9ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435664) - Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor) 1: 0 bundle [00:00, ? bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ea85f052904564b454223632996346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435664) - split(1, equal=True) 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4259634c646d4bdfa15518ac5cf016e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435664) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0acb6bdc095d4ce79d5e4cba31f82b86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435664) - Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor) 1: 0 bundle [00:00, ? bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19cff07c754e45b2acab48e8d24e577e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435664) - split(1, equal=True) 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3b11157fa464605a000b502344fc983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435664) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cadfdb26ba73491a81efae48409fe1e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435664) - Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor) 1: 0 bundle [00:00, ? bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5997d54b2f3d4bb8b5aab8a26b96f756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435664) - split(1, equal=True) 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28171d321d5f413da8ab514c16054f2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435664) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8715988063184429851543311d4feac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435665) - Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor) 1: 0 bundle [00:00, ? bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9917781046e48bd96f6aa025d62e9be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435665) - split(1, equal=True) 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff5a3d335b0d45938aeaeb5f2a993d2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435665) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ea40c1b45d74da8910cc1215e270363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435664) - Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor) 1: 0 bundle [00:00, ? bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5618873dd5a4458c948841cc38ff1ca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435664) - split(1, equal=True) 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c4a480c07b345d5b3a0c40770eb9995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435664) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ec2e89f05b741f0bccc240456434cf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435664) - Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor) 1: 0 bundle [00:00, ? bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c2fb5a9218f4b2ba8d868f8dc2b7005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435664) - split(1, equal=True) 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f30fb2e05dd4a2abe9af3112dcf3652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435664) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81617306efc44de0a18a04f6ee087551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435664) - Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor) 1: 0 bundle [00:00, ? bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f3af833793b4e9f8b5a328bfaa1d88b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435664) - split(1, equal=True) 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20881330efd44ec98053da51412d13a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435664) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30f5a495be524284b6b6224b397ad3e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435665) - Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor) 1: 0 bundle [00:00, ? bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44d644165a1f4373a707ce9e2ce255da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435665) - split(1, equal=True) 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc6cd41e155a4ace92c9873e3e6046fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435665) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d23cb6e2718643eda555f3fc61d6afda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435664) - Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor) 1: 0 bundle [00:00, ? bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9379b4193594cd78b33ddd548faff1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435664) - split(1, equal=True) 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0482076d71874e1492cdae6bd189c2be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435664) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d61dcafdcc8548de8482005f8e5d3f10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435664) - Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor) 1: 0 bundle [00:00, ? bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39f1eb6a84394930bccf3c9f1a25917c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435664) - split(1, equal=True) 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a86ab2aad04746a391e2f512521eb5d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435664) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b567fac65244c6a86895b9cba993fb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435664) - Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor) 1: 0 bundle [00:00, ? bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e825786044924a0f8fe7ad0adad6129d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435664) - split(1, equal=True) 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01cf5bb61380404ab8e667d60da37731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435664) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfc5520f61b0409983abc653fa5e57e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435665) - Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor) 1: 0 bundle [00:00, ? bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07b30884584d41159abd4871f6980947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435665) - split(1, equal=True) 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f1c186f1c844e0694068cedee385419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435665) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9820fb2b9b0947a29abb167582c8cdb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435664) - Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor) 1: 0 bundle [00:00, ? bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d83c2613aaeb4a0582dafae14b03e60d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435664) - split(1, equal=True) 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e48f312bb884b95a28d46b7d07e237b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435664) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "889befd0778048b4b7c2c6fa16f7f751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435664) - Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor) 1: 0 bundle [00:00, ? bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c90227407a444fda7eda3acebf0d33e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435664) - split(1, equal=True) 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "289e1f231f5647768b80b1aaf9eefa1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435664) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeede0b2c0b547dbae7babaa0b738c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435664) - Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor) 1: 0 bundle [00:00, ? bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3ac6360ad2c4cbc976cffcc0cc3047d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435664) - split(1, equal=True) 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "775f27fc04014b6aad8c14e084d789bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435664) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d31494a41b1e4a2db191599a6e536557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435665) - Map(TextDocumentProcessor)->Map(TikTokenizer)->FlatMap(ChunkProcessor) 1: 0 bundle [00:00, ? bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ad5edfbe134d30b36c5a44572caeff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435665) - split(1, equal=True) 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d0c3b3b478843198672d51c0cebdf2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=435665) Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-08-02 13:28:48 (running for 00:00:10.23)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-02_13-28-34_407310_432788/artifacts/2024-08-02_13-28-38/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 13:28:49,910\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/workspaces/CaiZi/outputs/gpt2/124M' in 0.0020s.\n",
      "2024-08-02 13:28:49,911\tINFO tune.py:1041 -- Total run time: 11.31 seconds (11.30 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-08-02 13:28:49 (running for 00:00:11.30)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 2.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2024-08-02_13-28-34_407310_432788/artifacts/2024-08-02_13-28-38/124M/driver_artifacts\n",
      "Number of trials: 1/1 (1 TERMINATED)\n",
      "\n",
      "\n",
      "{'epoch': 15, 'train_loss': 0.17282094061374664, 'validate_loss': 7.031112194061279, 'perplexity': 1131.2891845703125, 'best_epoch': 9, 'best_perplexity': 503.8351135253906, 'timestamp': 1722605328, 'checkpoint_dir_name': None, 'done': True, 'training_iteration': 5, 'trial_id': '208a2_00000', 'date': '2024-08-02_13-28-48', 'time_this_iter_s': 0.6792900562286377, 'time_total_s': 7.634586334228516, 'pid': 435232, 'hostname': '569d72e6c54c', 'node_ip': '172.17.0.2', 'config': {'train_loop_config': {'vocab_size': 50257, 'dimension_embedding': 768, 'block_size': 256, 'num_layers': 12, 'num_headers': 12, 'drop_rate': 0.1, 'qkv_bias': False, 'check_frequency': 3, 'batch_size_per_worker': 4, 'num_epoch_per_worker': 15, 'resume_training': True, 'best_checkpoint_dir': '/workspaces/CaiZi/model_weights/best_checkpoint'}}, 'time_since_restore': 7.634586334228516, 'iterations_since_restore': 5, 'experiment_tag': '0'}\n"
     ]
    }
   ],
   "source": [
    "from ray.train.torch import TorchTrainer\n",
    "from ray.train import Result\n",
    "from ray import train\n",
    "\n",
    "train_loop_config = {\n",
    "    \"vocab_size\": cfg[\"124M\"][\"vocab_size\"],\n",
    "    \"dimension_embedding\": cfg[\"124M\"][\"dimension_embedding\"],\n",
    "    \"block_size\": cfg[\"124M\"][\"block_size\"],\n",
    "    \"num_layers\": cfg[\"124M\"][\"num_layers\"],\n",
    "    \"num_headers\": cfg[\"124M\"][\"num_headers\"],\n",
    "    \"drop_rate\": cfg[\"124M\"][\"drop_rate\"],\n",
    "    \"qkv_bias\": cfg[\"124M\"][\"qkv_bias\"],\n",
    "    \"check_frequency\": cfg[\"ray_train\"][\"check_frequency\"],\n",
    "    \"batch_size_per_worker\": cfg[\"ray_train\"][\"batch_size_per_worker\"],\n",
    "    \"num_epoch_per_worker\": cfg[\"ray_train\"][\"num_epoch_per_worker\"],\n",
    "    \"resume_training\":cfg[\"ray_train\"][\"resume_training\"],\n",
    "    \"best_checkpoint_dir\":cfg[\"ray_train\"][\"best_checkpoint_dir\"],\n",
    "}\n",
    "\n",
    "\n",
    "trainer = TorchTrainer(\n",
    "    train_loop_per_worker=train_loop_per_worker,\n",
    "    train_loop_config=train_loop_config,\n",
    "    datasets={\n",
    "        \"train\": train_chunked_tokens,\n",
    "        \"validate\": validate_chunked_tokens,\n",
    "    },\n",
    "    scaling_config=ray.train.ScalingConfig(\n",
    "        num_workers=cfg[\"ray_train\"][\"num_workers\"],\n",
    "        use_gpu=cfg[\"ray_train\"][\"use_gpu\"],\n",
    "        resources_per_worker={\n",
    "            \"CPU\": cfg[\"ray_train\"][\"num_cpus_per_worker\"],\n",
    "            \"GPU\": cfg[\"ray_train\"][\"num_gpus_per_worker\"],\n",
    "        },\n",
    "    ),\n",
    "    run_config=train.RunConfig(\n",
    "        storage_path=cfg[\"ray_train\"][\"storage_path\"],\n",
    "        name=cfg[\"ray_train\"][\"name\"],\n",
    "    ),\n",
    "    \n",
    ")\n",
    "result: Result = trainer.fit()\n",
    "print(result.metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
